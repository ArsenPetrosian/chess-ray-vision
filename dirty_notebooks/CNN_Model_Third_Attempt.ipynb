{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Model_Third_Attempt.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Yk33mywbpcxd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PyTorch First Attempt"
      ]
    },
    {
      "metadata": {
        "id": "2JLf_jcWAi26",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "823e93f8-5fb4-45da-bc1f-7c0641d40f6c"
      },
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(f\"Gen RAM Free: {humanize.naturalsize( psutil.virtual_memory().available )} | Proc size: {humanize.naturalsize( process.memory_info().rss)}\")\n",
        "    print(f\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.9 GB | Proc size: 142.9 MB\n",
            "GPU RAM Free: 0MB | Used: 1MB | Util   2% | Total 3MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OgjeP1M8pcxe",
        "colab_type": "code",
        "outputId": "fac058f0-432e-4c5b-9110-ea2033814002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "cell_type": "code",
      "source": [
        "%%javascript\n",
        "IPython.OutputArea.prototype._should_scroll = function(lines) { return false; }\n",
        "// disable scrollable cells"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.OutputArea.prototype._should_scroll = function(lines) { return false; }\n",
              "// disable scrollable cells"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "iX8Q9D1Fpcxj",
        "colab_type": "code",
        "outputId": "7d0ac528-0e11-4f79-a28e-58655d3daa29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/samryan18/chess-ray-vision\n",
        "! git clone https://github.com/mukundv7/crvdataset\n",
        "! mv chess-ray-vision/clean_notebooks/* .\n",
        "# !mkdir chess\n",
        "# !mv chess-ray-vision/* chess"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'chess-ray-vision' already exists and is not an empty directory.\n",
            "fatal: destination path 'crvdataset' already exists and is not an empty directory.\n",
            "mv: cannot stat 'chess-ray-vision/clean_notebooks/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F41FgJIZIkBM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rVc5YZiHpcxl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup Stuff"
      ]
    },
    {
      "metadata": {
        "id": "G5YloGGWqY72",
        "colab_type": "code",
        "outputId": "b4f226eb-62a8-4b1c-b88c-4b0f826d2b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "# Pytorch Colab Setup\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "  \n",
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.0.1 from https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "joxmigYl9iK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "b459ae80-fc3d-4d8e-9854-f5f112097f1f"
      },
      "cell_type": "code",
      "source": [
        "## Required packages (Install in Colab)\n",
        "!pip install tensorflow\n",
        "!pip install scipy\n",
        "!pip install numpy\n",
        "!pip install Pillow\n",
        "!pip install image"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.8.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.14.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n",
            "Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.1.7)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.1.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.9)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wkGhAHeKpcxx",
        "colab_type": "code",
        "outputId": "83d002f5-9d6d-48b2-d4b1-0f4314468a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np;\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time, datetime\n",
        "from pytorch_general.pytorch_helper import imshow\n",
        "from pytorch_general.tensorboard_helper import Logger\n",
        "\n",
        "\n",
        "from typing import Callable\n",
        "import torch\n",
        "import dill\n",
        "import torch.optim as optim\n",
        "device =torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "OIq7Yn4mpmoD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "piece_symbols = 'prbnkqPRBNKQ'\n",
        "\n",
        "def onehot_from_fen(fen):\n",
        "    eye = np.eye(13)\n",
        "    output = np.empty((0, 13))\n",
        "    fen = re.sub('[-]', '', fen)\n",
        "\n",
        "    for char in fen:\n",
        "        if(char in '12345678'):\n",
        "            output = np.append(\n",
        "              output, np.tile(eye[12], (int(char), 1)), axis=0)\n",
        "        else:\n",
        "            idx = piece_symbols.index(char)\n",
        "            output = np.append(output, eye[idx].reshape((1, 13)), axis=0)\n",
        "\n",
        "    return output\n",
        "\n",
        "def fen_from_onehot(one_hot):\n",
        "    output = ''\n",
        "    for j in range(8):\n",
        "        for i in range(8):\n",
        "            if(one_hot[j][i] == 12):\n",
        "                output += ' '\n",
        "            else:\n",
        "                output += piece_symbols[one_hot[j][i]]\n",
        "        if(j != 7):\n",
        "            output += '-'\n",
        "\n",
        "    for i in range(8, 0, -1):\n",
        "        output = output.replace(' ' * i, str(i))\n",
        "\n",
        "    return output\n",
        "\n",
        "class_prob = onehot_from_fen('4kN1N-B1P5-QQ3B2-R1n1b3-8-1p2P3-1K6-6b1')\n",
        "\n",
        "# one_hot = np.zeros((64, 13))\n",
        "# one_hot[np.arange(64,13), class_labels] = 1\n",
        "# # class_labels\n",
        "# np.shape(class_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IvOPDfgUpcx0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LOG_DIR = './logs'\n",
        "# get_ipython().system_raw(\n",
        "#     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "#     .format(LOG_DIR)\n",
        "# )\n",
        "\n",
        "# !if [ -f ngrok ] ; then echo \"Ngrok already installed\" ; else wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1 && unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1 ; fi\n",
        "\n",
        "# get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "# ! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "#     \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QkeM2qiepcx3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/meditech101/chess-fen-generator-improved"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1uHyAjRIpcx5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AzTlMw2xpcx_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def load_datasets(directory='images/'):\n",
        "    pathlist = Path(directory).glob('**/*.jpeg')\n",
        "    labels = []\n",
        "    images = []\n",
        "    for path in pathlist:\n",
        "        label = str(path).split(directory)[1].split(f'.')[0]\n",
        "        label = onehot_from_fen(label)\n",
        "\n",
        "        img = np.asarray(Image.open(str(path))).astype('uint8')\n",
        "        labels.append(label)\n",
        "        images.append(img)\n",
        "        \n",
        "    test_images, test_labels = (images, labels) # TODO\n",
        "        \n",
        "    return images, labels, test_images, test_labels\n",
        "images, labels, test_images, test_labels = load_datasets()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eyai4agLpcyB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E6Ra4VjQpcyE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class CustomChessDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, transform=None, train=True):\n",
        "        train_images, train_labels, test_images, test_labels = load_datasets()\n",
        "        self.transform = transform\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "        if train:\n",
        "            self.images = train_images\n",
        "            self.labels = np.asarray(train_labels)\n",
        "            \n",
        "        else:\n",
        "            self.images = test_images\n",
        "            self.labels = np.asarray(test_labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        i = self.images[idx]\n",
        "        img_as_img = Image.fromarray(i)\n",
        "        img_as_img = img_as_img.convert('L')\n",
        "        \n",
        "#         _,class_labels = torch.max(self.to_tensor(self.labels[idx]).long().to(device),1) \n",
        "\n",
        "\n",
        "        return (self.to_tensor(img_as_img), \n",
        "                self.labels[idx])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-TQBjwIYpcyH",
        "colab_type": "code",
        "outputId": "6920b09a-07ba-4711-a89a-082ac948fe0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "cell_type": "code",
      "source": [
        "# Define a transform to normalize the data\n",
        "batch_size=50\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = CustomChessDataset(train=True, transform=transform)\n",
        "test_dataset = CustomChessDataset(train=False, transform =transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "print('normalized image example')\n",
        "image, label = next(iter(test_loader))\n",
        "imshow(image[0,:]);"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAE5CAYAAADr4VfxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "L84LWc3jpcyL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model: nn.Module, \n",
        "                log_dir: str,\n",
        "                train_loader,\n",
        "                criterion,\n",
        "                optimizer,\n",
        "                num_epochs,\n",
        "               log_freq) -> nn.Module:\n",
        "    t = datetime.datetime.now()\n",
        "    now = time.mktime(t.timetuple()) - 1550000000\n",
        "    logger = Logger(f'{log_dir} ({now})/')\n",
        "    \n",
        "    print(now)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    total_step = len(train_loader)\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0\n",
        "        for step, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.long().to(device)\n",
        "\n",
        "            output = model(images).to(device)\n",
        "            print(np.shape(labels))\n",
        "            print(np.shape(output))\n",
        "\n",
        "            _,class_labels = torch.max(labels,1) \n",
        "\n",
        "            loss = criterion(output, class_labels).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Compute accuracy\n",
        "            _, argmax = torch.max(output, 1)\n",
        "            accuracy = (class_labels == argmax.squeeze()).float().mean()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if step % log_freq == 0:\n",
        "\n",
        "                overall_step = epoch*total_step + step\n",
        "\n",
        "                # 1. Log scalar values (scalar summary)\n",
        "                info = { 'loss': loss.item(), 'accuracy': accuracy.item() }\n",
        "\n",
        "                for key, value in info.items():\n",
        "                    logger.scalar_summary(key, value, overall_step)\n",
        "\n",
        "                # 2. Log values and gradients of the parameters (histogram summary)\n",
        "                for key, value in model.named_parameters():\n",
        "                    key = key.replace('.', '/')\n",
        "                    logger.histo_summary(key, value.data.cpu().numpy(), overall_step)\n",
        "                    try:\n",
        "                        logger.histo_summary(key+'/grad', value.grad.data.cpu().numpy(), overall_step)\n",
        "                    except (AttributeError):\n",
        "                        # During transfer learning some of the variables don't have grads\n",
        "                        pass\n",
        "                        \n",
        "\n",
        "        print(f\"{epoch}: Training loss: {running_loss/len(train_loader)}\")\n",
        "        print(f\"{epoch}: Training accuracy: {accuracy}\")\n",
        " \n",
        "    return model\n",
        "\n",
        "\n",
        "def test_model(model, criterion, test_loader) -> float:\n",
        "    model = model.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    accuracies = []\n",
        "    losses = []\n",
        "    total_step = len(test_loader)\n",
        "    with torch.no_grad():\n",
        "        for i in range(total_step):\n",
        "            for  images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.long().to(device)\n",
        "                _,class_labels = torch.max(labels,1) \n",
        "\n",
        "                output = model(images)\n",
        "                loss = criterion(output, class_labels)\n",
        "                losses.append(loss.item())\n",
        "\n",
        "\n",
        "                # Compute accuracy\n",
        "                _, argmax = torch.max(output, 1)\n",
        "                accuracy = (class_labels == argmax.squeeze()).float().mean()\n",
        "                accuracies.append(accuracy)\n",
        "                \n",
        "    print(f'Accuracy of the network on test images: {np.average(accuracy.cpu())}')\n",
        "    print(f'Avg. Loss of the network on test images: {np.average(losses)}')\n",
        "\n",
        "    return np.average(accuracy.cpu())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7K27IuX2pcyP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, batch_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(400*400*1, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(4096, 2048),\n",
        "            nn.ReLU())\n",
        "        self.fc3 = nn.Sequential(\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU())\n",
        "        self.fc4 = nn.Sequential(\n",
        "            nn.Linear(1024, 64*13),\n",
        "            nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        out = self.fc1(x)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.fc4(out)\n",
        "        out = out.reshape(self.batch_size, 64, 13)\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2W2kijdBpcyV",
        "colab_type": "code",
        "outputId": "d32d81a6-871d-4114-fe98-87a41c7e0ff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        }
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "\n",
        "learning_rate = 0.001\n",
        "log_freq=25\n",
        "net = Net(batch_size=batch_size)\n",
        "      \n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "log_dir = f'./logs/PRELIM_lr{learning_rate}'\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "    \n",
        "model = train_model(net,\n",
        "                log_dir,\n",
        "                train_loader,\n",
        "                criterion,\n",
        "                optimizer,\n",
        "                num_epochs, log_freq)\n",
        "\n",
        "final_acc = test_model(model, criterion, test_loader)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4126533.0\n",
            "torch.Size([50, 64, 13])\n",
            "torch.Size([50, 64, 13])\n",
            "torch.Size([50, 64, 13])\n",
            "torch.Size([50, 64, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-27d8a5938206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 num_epochs, log_freq)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mfinal_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-4e2f87b30af3>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, log_dir, train_loader, criterion, optimizer, num_epochs, log_freq)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.98 GiB (GPU 0; 11.17 GiB total capacity; 8.23 GiB already allocated; 741.19 MiB free; 1.85 GiB cached)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "NnLTBOOrpcyr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZOU7Z3gxpcyt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Za8WUOnFHWEu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MJAB_gjrHWJ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c1aWhV1_HWRR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TtBdqd5rpcyx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mPlLCnefpcyy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "knTCzc3Gpcy9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ywR6A-Gepcy_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# %matplotlib inline\n",
        "\n",
        "# # from matplotlib.pyplot import imshow\n",
        "# # import matplotlib.pyplot as plt\n",
        "# from draw_chess_boards import *\n",
        "\n",
        "# renderer = DrawChessPosition(delimiter='-')\n",
        "# fen = \"r2q1rk1/pp2ppbp/1np2np1/2Q3B1/3PP1b1/2N2N2/PP3PPP/3RKB1R\"\n",
        "# fen = \"rnbqkbnr-pppppppp-8-8-8-8-PPPPPPPP-RNBQKBNR\"\n",
        "# board = renderer.draw(fen)\n",
        "# renderer.show(board)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RjDdiqGMpczC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.conv1 = nn.Sequential(\n",
        "#             nn.Conv2d(400*400*1, 32, 4),\n",
        "#             nn.BatchNorm2d(32),\n",
        "#             nn.MaxPool2d(2, 2),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.conv2 = nn.Sequential(\n",
        "#             nn.Conv2d(400*400*1, 1024, 24),\n",
        "#             nn.BatchNorm2d(32),\n",
        "#             nn.MaxPool2d(12, 12),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.fc1 = nn.Sequential(\n",
        "#             nn.Linear(1024, 64*52),\n",
        "#             nn.ReLU())\n",
        "#         self.fc2 = nn.Sequential(\n",
        "#             nn.Linear(64*52, 64*52),\n",
        "#             nn.ReLU())\n",
        "#         self.fc3 = nn.Sequential(\n",
        "#             nn.Linear(64*52, 64*26),\n",
        "#             nn.ReLU())\n",
        "#         self.fc4 = nn.Sequential(\n",
        "#             nn.Linear(64*26, 64*13),\n",
        "#             nn.ReLU())\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = x.view(x.shape[0], -1)\n",
        "#         out = self.conv1(x)\n",
        "#         out = self.fc1(out)\n",
        "#         out = self.fc2(out)\n",
        "#         out = self.fc3(out)\n",
        "#         out = self.fc4(out)\n",
        "#         out = out.reshape(1, 64, 13)\n",
        "# #         out = F.log_softmax(out, dim=2)\n",
        "\n",
        "# #         out = F.log_softmax(self.fc6(out.reshape(1, 64, 13)), dim=1)\n",
        "\n",
        "#         return out\n",
        "    \n",
        "    \n",
        "# # class CNN(nn.Module):\n",
        "# #     def __init__(self):\n",
        "# #         super(CNN, self).__init__()\n",
        "\n",
        "# #         self.conv1 = nn.Conv2d(3, 32, 4)\n",
        "# #         self.bn1 = nn.BatchNorm2d(32)\n",
        "# #         self.pool1 = nn.MaxPool2d(2, 2)\n",
        "# #         self.dropout1 = nn.Dropout(p = 0.1)\n",
        "\n",
        "# #         self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "# #         self.bn2 = nn.BatchNorm2d(64)\n",
        "# #         self.pool2 = nn.MaxPool2d(2, 2)\n",
        "# #         self.dropout2 = nn.Dropout(p = 0.2)\n",
        "\n",
        "# #         self.conv3 = nn.Conv2d(64, 128, 2)\n",
        "# #         self.bn3 = nn.BatchNorm2d(128)\n",
        "# #         self.pool3 = nn.MaxPool2d(2, 2)\n",
        "# #         self.dropout3 = nn.Dropout(p = 0.3)\n",
        "\n",
        "# #         self.conv4 = nn.Conv2d(128, 256, 3)\n",
        "# #         self.bn4 = nn.BatchNorm2d(256)\n",
        "# #         self.pool4 = nn.MaxPool2d(2, 2)\n",
        "# #         self.dropout4 = nn.Dropout(p = 0.4)\n",
        "\n",
        "# #         self.fc1 = nn.Linear(256*12*12, 1000)\n",
        "# #         self.dropout5 = nn.Dropout(p = 0.5)\n",
        "# #         self.fc2 = nn.Linear(1000, 1000)\n",
        "# #         self.dropout6 = nn.Dropout(p = 0.6)\n",
        "# #         self.fc3 = nn.Linear(1000, 250)\n",
        "# #         self.dropout7 = nn.Dropout(p = 0.7)\n",
        "# #         self.fc4 = nn.Linear(250, 120)\n",
        "\n",
        "\n",
        "# #     def forward(self, x):\n",
        "# #         x = self.dropout1(self.pool1(F.relu(self.bn1(self.conv1(x)))))\n",
        "# #         x = self.dropout2(self.pool2(F.relu(self.bn2(self.conv2(x)))))\n",
        "# #         x = self.dropout3(self.pool3(F.relu(self.bn3(self.conv3(x)))))\n",
        "# #         x = self.dropout4(self.pool4(F.relu(self.bn4(self.conv4(x)))))\n",
        "# #         x = x.view(x.size(0), -1)\n",
        "# #         x = self.dropout5(self.fc1(x))\n",
        "# #         x = self.dropout6(self.fc2(x))\n",
        "# #         x = self.dropout7(self.fc3(x))\n",
        "# #         x = self.fc4(x)\n",
        "# #         x = F.log_softmax(x, dim=1)\n",
        "# #         return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UATYG6EdpczE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def train(model, optimizer, loss_fn, dataloader, metrics, params):\n",
        "#     \"\"\"Train the model on `num_steps` batches\n",
        "\n",
        "#     Args:\n",
        "#         model: (torch.nn.Module) the neural network\n",
        "#         optimizer: (torch.optim) optimizer for parameters of model\n",
        "#         loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
        "#         dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches training data\n",
        "#         metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
        "#         params: (Params) hyperparameters\n",
        "#         num_steps: (int) number of batches to train on, each of size params.batch_size\n",
        "#     \"\"\"\n",
        "\n",
        "#     # set model to training mode\n",
        "#     model.train()\n",
        "\n",
        "#     # summary for current training loop and a running average object for loss\n",
        "#     summ = []\n",
        "#     loss_avg = RunningAverage()\n",
        "\n",
        "#     # Use tqdm for progress bar\n",
        "#     with tqdm(total=len(dataloader)) as t:\n",
        "#         for i, (train_batch, labels_batch) in enumerate(dataloader):\n",
        "#             # move to GPU if available\n",
        "#             if params.cuda:\n",
        "#                 train_batch, labels_batch = train_batch.cuda(async=True), labels_batch.cuda(async=True)\n",
        "#             # convert to torch Variables\n",
        "#             train_batch, labels_batch = Variable(train_batch), Variable(labels_batch)\n",
        "\n",
        "#             # compute model output and loss\n",
        "#             output_batch = model(train_batch)\n",
        "#             #logger.debug(\"train output_batch.shape = {}. labels_batch.shape = {}\".format(output_batch.shape, labels_batch.shape))\n",
        "\n",
        "#             # check if predictions are negative\n",
        "#             logger.info(\"negative predictions: {}\".format((output_batch < 0.0).any()))\n",
        "\n",
        "#             # compute loss\n",
        "#             loss = loss_fn(output_batch, labels_batch)\n",
        "#             logger.debug(\"loss: {}\".format(loss.data.item()))\n",
        "\n",
        "#             # clear previous gradients, compute gradients of all variables wrt loss\n",
        "#             optimizer.zero_grad()\n",
        "#             loss.backward()\n",
        "\n",
        "#             # performs updates using calculated gradients\n",
        "#             optimizer.step()\n",
        "\n",
        "#             # Evaluate summaries only once in a while\n",
        "#             if i % params.save_summary_steps == 0:\n",
        "#                 # extract data from torch Variable, move to cpu, convert to numpy arrays\n",
        "#                 output_batch = output_batch.data.cpu().numpy()\n",
        "#                 labels_batch = labels_batch.data.cpu().numpy()\n",
        "\n",
        "#                 # compute all metrics on this batch\n",
        "#                 summary_batch = {metric:metrics[metric](output_batch, labels_batch)\n",
        "#                                  for metric in metrics}\n",
        "#                 summary_batch['loss'] = loss.data.item()\n",
        "#                 summ.append(summary_batch)\n",
        "\n",
        "#             # update the average loss\n",
        "#             loss_avg.update(loss.data.item())\n",
        "\n",
        "#             t.set_postfix(loss='{:05.3f}'.format(loss_avg()))\n",
        "#             t.update()\n",
        "\n",
        "#     # compute mean of all metrics in summary\n",
        "#     metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]}\n",
        "#     metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_mean.items())\n",
        "#     logger.info(\"- Train metrics: \" + metrics_string)\n",
        "\n",
        "\n",
        "# def train_and_evaluate(model, train_dataloader, val_dataloader, optimizer, loss_fn, metrics, params, model_dir,\n",
        "#                        restore_file=None):\n",
        "#     \"\"\"Train the model and evaluate every epoch.\n",
        "\n",
        "#     Args:\n",
        "#         model: (torch.nn.Module) the neural network\n",
        "#         train_dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches training data\n",
        "#         val_dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches validation data\n",
        "#         optimizer: (torch.optim) optimizer for parameters of model\n",
        "#         loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
        "#         metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
        "#         params: (Params) hyperparameters\n",
        "#         model_dir: (string) directory containing config, weights and log\n",
        "#         restore_file: (string) optional- name of file to restore from (without its extension .pth.tar)\n",
        "#     \"\"\"\n",
        "\n",
        "#     # reload weights from restore_file if specified\n",
        "#     if restore_file is not None:\n",
        "#         restore_path = os.path.join(model_dir, restore_file + '.pth.tar')\n",
        "#         logger.info(\"Restoring parameters from {}\".format(restore_path))\n",
        "#         load_checkpoint(restore_path, model, optimizer)\n",
        "\n",
        "#     best_val_acc = 0.0\n",
        "\n",
        "#     for epoch in range(params.num_epochs):\n",
        "#         # Run one epoch\n",
        "#         logger.info(\"Epoch {}/{}\".format(epoch + 1, params.num_epochs))\n",
        "\n",
        "#         # compute number of batches in one epoch (one full pass over the training set)\n",
        "#         train(model, optimizer, loss_fn, train_dataloader, metrics=metrics, params=params)\n",
        "\n",
        "#         # Evaluate for one epoch on validation set\n",
        "#         val_metrics = evaluate(model, loss_fn, val_dataloader, metrics=metrics, params=params)\n",
        "\n",
        "#         # TODO: Fix TypeError: 'NoneType' object is not subscriptable\n",
        "#         val_acc = val_metrics['accuracy']\n",
        "#         is_best = val_acc>=best_val_acc\n",
        "\n",
        "#         # Save weights\n",
        "#         save_checkpoint({'epoch': epoch + 1,\n",
        "#                          'state_dict': model.state_dict(),\n",
        "#                          'optim_dict' : optimizer.state_dict()},\n",
        "#                           is_best=is_best,\n",
        "#                           checkpoint=model_dir)\n",
        "\n",
        "#         # If best_eval, best_save_path\n",
        "#         if is_best:\n",
        "#             logger.info(\"- Found new best accuracy\")\n",
        "#             best_val_acc = val_acc\n",
        "\n",
        "#             # Save best val metrics in a json file in the model directory\n",
        "#             best_json_path = os.path.join(model_dir, \"metrics_val_best_weights.json\")\n",
        "#             save_dict_to_json(val_metrics, best_json_path)\n",
        "\n",
        "#         # Save latest val metrics in a json file in the model directory\n",
        "#         last_json_path = os.path.join(model_dir, \"metrics_val_last_weights.json\")\n",
        "#         save_dict_to_json(val_metrics, last_json_path)\n",
        "\n",
        "# def main():\n",
        "#     # print some log messages\n",
        "#     logger.info(\"DSTL Satellite Imagery Feature Detection - Train U-Net Model\")\n",
        "\n",
        "#     # load parameters\n",
        "#     # load parameters from configuration file\n",
        "#     params = Params('experiment/unet_model/params_3ch.yaml', ParameterFileType.YAML, ctx=None)\n",
        "\n",
        "#     # parameters\n",
        "#     logger.debug(\"parameters: \\n{}\\n\".format(pformat(params.dict)))\n",
        "\n",
        "#     # use GPU if available\n",
        "#     params.cuda = torch.cuda.is_available()\n",
        "\n",
        "#     # Set the random seed for reproducible experiments\n",
        "#     torch.manual_seed(230)\n",
        "#     if params.cuda:\n",
        "#         torch.cuda.manual_seed(230)\n",
        "\n",
        "#     # dataset parameters, which includes download, input, output and mask generation parameters.\n",
        "#     dataset_params = params.dataset\n",
        "#     logger.debug(\"dataset parameters: \\n{}\\n\".format(pformat(dataset_params)))\n",
        "\n",
        "#     # dataset\n",
        "#     logger.info(\"loading datasets...\")\n",
        "#     train_set = DSTLSIFDDataset(dataset_params=dataset_params,\n",
        "#                                 mode='train',\n",
        "#                                 transform=True,\n",
        "#                                 transform_mask=None,\n",
        "#                                 download=False)\n",
        "\n",
        "#     dev_set   = DSTLSIFDDataset(dataset_params=dataset_params,\n",
        "#                                 mode='dev',\n",
        "#                                 transform=True,\n",
        "#                                 transform_mask=None,\n",
        "#                                 download=False)\n",
        "\n",
        "#     # dataloader\n",
        "#     logger.debug(\"train dataloader, batch size: {}, num workers: {}, cuda: {}\".format(\n",
        "#         params.train['batch_size'],\n",
        "#         params.train['num_workers'],\n",
        "#         params.cuda));\n",
        "\n",
        "#     train_dl = DataLoader(dataset=train_set,\n",
        "#                           batch_size=params.train['batch_size'],\n",
        "#                           shuffle=True,\n",
        "#                           num_workers=params.train['num_workers'],\n",
        "#                           pin_memory=params.cuda)\n",
        "\n",
        "#     logger.debug(\"dev dataloader, batch size: {}, num workers: {}, cuda: {}\".format(\n",
        "#         params.valid['batch_size'],\n",
        "#         params.valid['num_workers'],\n",
        "#         params.cuda));\n",
        "\n",
        "#     valid_dl = DataLoader(dataset=dev_set,\n",
        "#                           batch_size=params.valid['batch_size'],\n",
        "#                           shuffle=True,\n",
        "#                           num_workers=params.valid['num_workers'],\n",
        "#                           pin_memory=params.cuda)\n",
        "\n",
        "#     logger.info(\"- done.\")\n",
        "\n",
        "#     # define the model and optimizer\n",
        "#     #model = UNet()\n",
        "#     model = UNet().cuda() if params.cuda else UNet()\n",
        "#     logger.info(\"using adam optimized with lr = {}\".format(float(params.learning_rate)))\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=float(params.learning_rate))\n",
        "\n",
        "#     # loss function\n",
        "#     loss_fn = multi_class_cross_entropy_loss  # nn.MSELoss()  # nn.L1Loss() # nn.CrossEntropyLoss()\n",
        "\n",
        "#     # maintain all metrics required in this dictionary- these are used in the training and evaluation loops\n",
        "#     metrics = {\n",
        "#         'accuracy': accuracy,\n",
        "#         # could add more metrics such as accuracy for each token type\n",
        "#     }\n",
        "\n",
        "#     # train the model\n",
        "#     logger.info(\"Starting training for {} epoch(s)\".format(params.num_epochs))\n",
        "\n",
        "#     data_dir = \"data/\"\n",
        "#     model_dir = \"experiment/unet_model\"\n",
        "\n",
        "#     train_and_evaluate(model=model,\n",
        "#                        train_dataloader=train_dl,\n",
        "#                        val_dataloader=valid_dl,\n",
        "#                        optimizer=optimizer,\n",
        "#                        loss_fn=loss_fn,\n",
        "#                        metrics=metrics,\n",
        "#                        params=params,\n",
        "#                        model_dir=data_dir,\n",
        "#                        restore_file=None)\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}