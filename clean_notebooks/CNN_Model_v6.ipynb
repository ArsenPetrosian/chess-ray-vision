{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Model_v6.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "Yk33mywbpcxd"
      },
      "cell_type": "markdown",
      "source": [
        "# PyTorch Model on Dummy Dataset (v6)\n",
        "\n",
        "#### Chess Board Object Detection\n",
        "\n",
        "#### CIS 520, Spring 2019\n",
        "\n",
        "This notebook is written to run on [Google Colab](https://colab.research.google.com/notebook). \n",
        "\n",
        "----\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2JLf_jcWAi26",
        "outputId": "40331e3c-8fef-404a-f334-0743ac67af90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# # Check out available CPU and GPU memory\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "def print_CPU_GPU_info(GPUs):\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(f\"\\nCPU \\tRAM Free: {humanize.naturalsize(psutil.virtual_memory().available)}\"\n",
        "          f\"    | Proc size: {humanize.naturalsize(process.memory_info().rss)}\")\n",
        "    if GPUs[0]: \n",
        "        for i,gpu in enumerate(GPUs):\n",
        "            print(f\"GPU {i} \\tRAM Free: {gpu.memoryFree/1000:.3f} GB  \"\n",
        "                  f\"| Used: {gpu.memoryUsed/1000:.3f} GB\"\n",
        "                  f\"\\t| Utilization: {gpu.memoryUtil*100:3.0f}% | \"\n",
        "                  f\"Total Memory: {gpu.memoryTotal/1000:.3f} GB\")\n",
        "    else: print(f\"Not on a GPU\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tl7BZKJuOQ4t",
        "outputId": "3a147ea5-328c-4c92-a4d3-df90c51cea8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print_CPU_GPU_info(GPU.getGPUs())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU \tRAM Free: 12.9 GB    | Proc size: 142.0 MB\n",
            "GPU 0 \tRAM Free: 11.441 GB  | Used: 0.000 GB\t| Utilization:   0% | Total Memory: 11.441 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OgjeP1M8pcxe",
        "outputId": "f0eace9e-7720-4c67-e56d-c216fedfe8bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "cell_type": "code",
      "source": [
        "%%javascript\n",
        "IPython.OutputArea.prototype._should_scroll = function(lines) { return false; }\n",
        "// disable scrollable cells"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.OutputArea.prototype._should_scroll = function(lines) { return false; }\n",
              "// disable scrollable cells"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "c6f5WavtHSJb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # ! rm -rf pytorch_general\n",
        "# # ! rm pytorch_general\n",
        "# # ! rm -rf images\n",
        "# # ! rm -rf piece_images\n",
        "# ! rm -rf chess-ray-vision\n",
        "# ! rm -rf utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iX8Q9D1Fpcxj",
        "outputId": "b02b4754-7352-42b6-8a43-d4726ecc85ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/samryan18/chess-ray-vision\n",
        "! mv chess-ray-vision/clean_notebooks/* .\n",
        "\n",
        "\n",
        "#NOTE this next line will download 2+ GB of data\n",
        "#Do not run locally unless your comp can take that kinda heat\n",
        "! git clone https://github.com/mukundv7/crvdataset \n",
        "! mkdir train_full\n",
        "! mv crvdataset/chess-positions/train-full/* train_full/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'chess-ray-vision' already exists and is not an empty directory.\n",
            "mv: cannot stat 'chess-ray-vision/clean_notebooks/*': No such file or directory\n",
            "fatal: destination path 'crvdataset' already exists and is not an empty directory.\n",
            "mkdir: cannot create directory ‘train_full’: File exists\n",
            "mv: cannot stat 'crvdataset/chess-positions/train-full/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "rVc5YZiHpcxl"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup Stuff"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "G5YloGGWqY72",
        "outputId": "9b3965f2-6be4-442f-e701-17aa9ad725c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "# Pytorch Colab Setup\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "  \n",
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.0.1 from https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "joxmigYl9iK9",
        "outputId": "d6e37b98-73d6-49e5-f6c8-4e92095f0b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "cell_type": "code",
      "source": [
        "## Required packages (Install in Colab)\n",
        "!pip install tensorflow\n",
        "!pip install scipy\n",
        "!pip install numpy\n",
        "!pip install Pillow\n",
        "!pip install image\n",
        "!pip install torchviz\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.14.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n",
            "Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.1.7)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.1.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.9)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n",
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wkGhAHeKpcxx",
        "outputId": "fb807106-97a3-410f-bc40-dd5d6ddeb05a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "####################################################\n",
        "# CODE IMPORTS\n",
        "\n",
        "from pytorch_general.pytorch_helper import imshow\n",
        "from pytorch_general.tensorboard_helper import Logger\n",
        "from utils.data_loading_utils import (onehot_from_fen, fen_from_onehot, \n",
        "                                     fen_from_64, fen_from_filename, \n",
        "                                     process_image)\n",
        "from utils.draw_chess_boards import DrawChessPosition\n",
        "\n",
        "####################################################\n",
        "# EXTERNAL IMPORTS\n",
        "\n",
        "import torchvision\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import numpy as np;\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time, datetime\n",
        "from tqdm import tqdm\n",
        "from torchsummary import summary\n",
        "\n",
        "from random import randint\n",
        "\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from random import shuffle\n",
        "import os\n",
        "\n",
        "\n",
        "import glob\n",
        "\n",
        "import torch.optim as optim\n",
        "device =torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OIq7Yn4mpmoD",
        "outputId": "c45568b4-d614-49e8-c407-0b11cb862481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "fen = '4kN1N-bbbbbbbb-QQ3B2-R1n1b3-8-8-ppqKbKbk-8'\n",
        "class_prob = onehot_from_fen(fen)\n",
        "\n",
        "print(f\"Original: \\t{fen}\")\n",
        "print(f\"Reconstructed:  {fen_from_onehot(class_prob)}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: \t4kN1N-bbbbbbbb-QQ3B2-R1n1b3-8-8-ppqKbKbk-8\n",
            "Reconstructed:  4kN1N-bbbbbbbb-QQ3B2-R1n1b3-8-8-ppqKbKbk-8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jprHKvxU8D0M",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CustomChessDataset(Dataset):\n",
        "    \"\"\"Chess dataset\"\"\"\n",
        "\n",
        "    def __init__(self, \n",
        "                 transform=None,\n",
        "                 root='train_full',\n",
        "                 train_size = 10000,\n",
        "                 test_size = 3000,\n",
        "                 downsample_size = 200,\n",
        "                 train=True):\n",
        "\n",
        "        self._train = train\n",
        "        self.downsample_size = downsample_size\n",
        "            \n",
        "        self.root = root\n",
        "        self.pathlist = list(Path(self.root).glob('**/*.jpeg'))\n",
        "        self.n_files = len(self.pathlist)\n",
        "        \n",
        "        self.train_size = train_size\n",
        "        self.test_size = test_size\n",
        "\n",
        "        self.train = glob.glob(f\"{root}/*.jpeg\")\n",
        "        self.test = glob.glob(f\"{root}/*.jpeg\")\n",
        "\n",
        "        shuffle(self.train)\n",
        "        shuffle(self.test)\n",
        "\n",
        "        self.train = self.train[:self.train_size]\n",
        "        self.test = self.test[:self.test_size]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.train_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.train[idx]\n",
        "        label = onehot_from_fen(fen_from_filename(img))\n",
        "        img_as_img, original_img = process_image(img, \n",
        "                                                 downsample_size = self.downsample_size)\n",
        "\n",
        "        return ((torch.from_numpy(img_as_img).float()), \n",
        "                label,\n",
        "                original_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eyai4agLpcyB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# BATCH_SIZE needs to be small ish bc bigger models will scale \n",
        "# memory usage exponentially\n",
        "BATCH_SIZE=10 \n",
        "downsample_size=200\n",
        "transform = transforms.Compose([transforms.Resize(downsample_size)])\n",
        "\n",
        "train_dataset = CustomChessDataset(root='train_full/', train=True, \n",
        "                                   downsample_size=downsample_size)\n",
        "test_dataset = CustomChessDataset(root='train_full/', train=False, \n",
        "                                  downsample_size=downsample_size)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L84LWc3jpcyL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model: nn.Module, \n",
        "                log_dir: str,\n",
        "                train_loader: torch.utils.data.DataLoader,\n",
        "                criterion: torch.nn.modules.Module,\n",
        "                optimizer: torch.optim.Optimizer,\n",
        "                num_epochs: int=1,\n",
        "                log_freq: int=25,\n",
        "                print_guess=False,\n",
        "                print_guess_freq=50) -> nn.Module:\n",
        "    \n",
        "    # Create Logging Directory for Tensorboard\n",
        "    now = time.mktime(datetime.datetime.now().timetuple()) - 1550000000\n",
        "    log_dir = f'{log_dir} ({now})/'\n",
        "    logger = Logger(log_dir)\n",
        "    print(f'Training model. Logging to: \"{log_dir}\"\\n')\n",
        "\n",
        "    model = model.to(device) # Send model to GPU if possible\n",
        "    model.train() # Set model to training mode\n",
        "\n",
        "    total_step = len(train_loader)\n",
        "    for epoch in range(num_epochs):\n",
        "        if print_guess: print(f'Epoch {epoch}')\n",
        "        running_loss = 0\n",
        "        \n",
        "        # Tqdm will create a progress bar\n",
        "        with tqdm(total=len(train_loader), \n",
        "                  desc=f'Epoch {epoch}', \n",
        "                  unit=' minibatches',\n",
        "                  disable=(print_guess)) as pbar:\n",
        "            \n",
        "            # Iterate through minibatches\n",
        "            for step, (images, labels, original_imgs) in enumerate(train_loader):\n",
        "                images, labels = images.to(device), labels.long().to(device)\n",
        "\n",
        "                output = model(images).to(device)\n",
        "                _,class_labels = torch.max(labels,2) \n",
        "                _, argmax = torch.max(output, 2)\n",
        "\n",
        "                accuracy = float((class_labels == \n",
        "                                  argmax.squeeze()).float().mean().cpu())\n",
        "\n",
        "                loss = criterion(output.reshape(10*64,13).float(),\n",
        "                                 class_labels.reshape(10*64))\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "\n",
        "                running_loss += float(loss.item())\n",
        "                \n",
        "                pbar.set_postfix(training_accuracy=accuracy, loss=loss.item(), refresh=True)\n",
        "                pbar.update(1)\n",
        "                \n",
        "                if step % log_freq == 0:\n",
        "                    overall_step = epoch*total_step + step\n",
        "\n",
        "                    # 1. Log scalar values (scalar summary)\n",
        "                    info = { 'loss': loss.item(), 'accuracy': accuracy }\n",
        "\n",
        "                    for key, value in info.items():\n",
        "                        logger.scalar_summary(key, value, overall_step)\n",
        "\n",
        "                    # 2. Log values and gradients of the parameters\n",
        "                    # (histogram summary)\n",
        "                    for key, value in model.named_parameters():\n",
        "                        key = key.replace('.', '/')\n",
        "                        logger.histo_summary(key, \n",
        "                                             value.data.cpu().numpy(), \n",
        "                                             overall_step)\n",
        "                        try:\n",
        "                            logger.histo_summary(key+'/grad', \n",
        "                                                 value.grad.data.cpu().numpy(),\n",
        "                                                 overall_step)\n",
        "                        except (AttributeError):\n",
        "                            # During transfer learning some of the variables \n",
        "                            # don't have grads\n",
        "                            pass\n",
        "    \n",
        "                if print_guess and step % print_guess_freq == 0:\n",
        "\n",
        "                    overall_step = epoch*total_step + step\n",
        "                    print(f\"\\n{60*'-'}\\nBatch Number: {overall_step}\")\n",
        "                    print(f\"Example training point:\")\n",
        "                    print(f\"Actual: {fen_from_64(class_labels.cpu()[0])}\")\n",
        "                    print(f\"Guess: {fen_from_64(argmax.cpu()[0])}\")\n",
        "                    print(f\"Example Accuracy: {float((class_labels[0] == argmax[0]).float().mean().cpu())}\")\n",
        "                    \n",
        "                    renderer = DrawChessPosition(delimiter='-')\n",
        "                    board_actual = renderer.draw(fen_from_64(class_labels.cpu()[0]))\n",
        "                    board_guess = renderer.draw(fen_from_64(argmax.cpu()[0]))\n",
        "                    renderer.show_side_by_side(board1= original_imgs[0],\n",
        "                                               board2=board_guess, \n",
        "                                               board1_title='Actual',\n",
        "                                               board2_title='Prediction (Re'\n",
        "                                                            'ndered to image)')\n",
        "        print(f\"{epoch}: Training loss: {running_loss/len(train_loader)}\")\n",
        "        print(f\"{epoch}: Training accuracy: {accuracy}\")\n",
        " \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def test_model(model, criterion, test_loader) -> float:\n",
        "    \n",
        "    '''\n",
        "    TODO: REWRITE THIS\n",
        "    '''\n",
        "    model = model.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    accuracies = []\n",
        "    losses = []\n",
        "    total_step = len(test_loader)\n",
        "    with torch.no_grad():\n",
        "        for i in range(total_step):\n",
        "            for  images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.long().to(device)\n",
        "                _,class_labels = torch.max(labels,1) \n",
        "\n",
        "                output = model(images).to(device)\n",
        "                loss = criterion(output, class_labels)\n",
        "                losses.append(float(loss.item()))\n",
        "\n",
        "\n",
        "                # Compute accuracy\n",
        "                _, argmax = torch.max(output, 1)\n",
        "                accuracy = float((class_labels == argmax.squeeze()).float().mean().cpu())\n",
        "                accuracies.append(accuracy)\n",
        "                \n",
        "    print(f'Accuracy of the network on test images: {np.average(accuracies)}')\n",
        "    print(f'Avg. Loss of the network on test images: {np.average(losses)}')\n",
        "\n",
        "    return np.average(accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LC5DpAfNRVUL"
      },
      "cell_type": "markdown",
      "source": [
        "# Models"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HRQAmGX57yo0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1) \n",
        "\n",
        "class SimpleCNN(torch.nn.Module):\n",
        "    def __init__(self, batch_size):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.name = 'SimpleCNN'\n",
        "        self.batch_size=batch_size\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1),\n",
        "            nn.LeakyReLU(negative_slope=0.1))\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1),\n",
        "            nn.ReLU())\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1),\n",
        "            nn.ReLU())\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(32*19*19, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.1))\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(256, 13))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(self.batch_size*64,3,25,25)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        \n",
        "        x = self.flatten(x)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "#         print(f'xsize: {x.size()}')\n",
        "        x = x.reshape(self.batch_size,64,13)\n",
        "\n",
        "        return(x)\n",
        "    \n",
        "class BiggerCNN(torch.nn.Module):\n",
        "    def __init__(self, batch_size):\n",
        "        super(BiggerCNN, self).__init__()\n",
        "        self.name = 'BiggerCNN'\n",
        "        self.batch_size=batch_size\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.LeakyReLU(negative_slope=0.1))\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.ReLU())\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.ReLU())\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(64*19*19, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.1))\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.1))\n",
        "        self.fc3 = nn.Sequential(\n",
        "            nn.Linear(256, 13))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(self.batch_size*64,3,25,25)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        \n",
        "        x = self.flatten(x)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "#         print(f'xsize: {x.size()}')\n",
        "        x = x.reshape(self.batch_size,64,13)\n",
        "\n",
        "        return(x)\n",
        "    \n",
        "class BiggerCNN_No_Dropout(torch.nn.Module):\n",
        "    def __init__(self, batch_size):\n",
        "        super(BiggerCNN_No_Dropout, self).__init__()\n",
        "        self.name = 'BiggerCNN_No_Dropout'\n",
        "        self.batch_size=batch_size\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.LeakyReLU(negative_slope=0.1))\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.ReLU())\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.ReLU())\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(64*19*19, 512),\n",
        "            nn.ReLU())\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU())\n",
        "        self.fc3 = nn.Sequential(\n",
        "            nn.Linear(256, 13))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(self.batch_size*64,3,25,25)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        \n",
        "        x = self.flatten(x)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "#         print(f'xsize: {x.size()}')\n",
        "        x = x.reshape(self.batch_size,64,13)\n",
        "\n",
        "        return(x)\n",
        "    \n",
        "    \n",
        "# class MoreSkinnierLayersBiggerCNN(torch.nn.Module):\n",
        "#     def __init__(self, batch_size):\n",
        "#         super(MoreSkinnierLayersBiggerCNN, self).__init__()\n",
        "#         self.name = 'MoreSkinnierLayersBiggerCNN'\n",
        "#         self.batch_size=batch_size\n",
        "#         self.conv1 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1),\n",
        "#             nn.LeakyReLU(negative_slope=0.1))\n",
        "#         self.conv2 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride=1),\n",
        "#             nn.ReLU())\n",
        "#         self.conv3 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1),\n",
        "#             nn.ReLU())\n",
        "#         self.conv4 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1),\n",
        "#             nn.ReLU())\n",
        "#         self.conv5 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1),\n",
        "#             nn.ReLU())\n",
        "#         self.flatten = Flatten()\n",
        "#         self.fc1 = nn.Sequential(\n",
        "#             nn.Linear(640*2704, 512),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.fc2 = nn.Sequential(\n",
        "#             nn.Linear(512, 256),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.fc3 = nn.Sequential(\n",
        "#             nn.Linear(256, 13))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = x.reshape(self.batch_size*64,3,25,25)\n",
        "\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.conv2(x)\n",
        "#         x = self.conv3(x)\n",
        "#         x = self.conv3(x)\n",
        "#         x = self.conv4(x)\n",
        "#         x = self.conv5(x)\n",
        "        \n",
        "#         x = self.flatten(x)\n",
        "        \n",
        "#         x = self.fc1(x)\n",
        "#         x = self.fc2(x)\n",
        "#         x = self.fc3(x)\n",
        "\n",
        "# #         print(f'xsize: {x.size()}')\n",
        "#         x = x.reshape(self.batch_size,64,13)\n",
        "\n",
        "#         return(x)\n",
        "\n",
        "    \n",
        "# class BatchNormBiggerCNN(torch.nn.Module):\n",
        "#     def __init__(self, batch_size):\n",
        "#         super(BatchNormBiggerCNN, self).__init__()\n",
        "#         self.name = 'BatchNormBiggerCNN'\n",
        "#         self.batch_size=batch_size\n",
        "#         self.conv1 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1),\n",
        "#             nn.BatchNorm2d(64),\n",
        "#             nn.LeakyReLU(negative_slope=0.1),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.conv2 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "#             nn.BatchNorm2d(64),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.conv3 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "#             nn.ReLU())\n",
        "#         self.flatten = Flatten()\n",
        "#         self.fc1 = nn.Sequential(\n",
        "#             nn.Linear(64*19*19, 512),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.fc2 = nn.Sequential(\n",
        "#             nn.Linear(512, 256),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.fc3 = nn.Sequential(\n",
        "#             nn.Linear(256, 13))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = x.reshape(self.batch_size*64,3,25,25)\n",
        "\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.conv2(x)\n",
        "#         x = self.conv3(x)\n",
        "        \n",
        "#         x = self.flatten(x)\n",
        "        \n",
        "#         x = self.fc1(x)\n",
        "#         x = self.fc2(x)\n",
        "#         x = self.fc3(x)\n",
        "\n",
        "# #         print(f'xsize: {x.size()}')\n",
        "#         x = x.reshape(self.batch_size,64,13)\n",
        "\n",
        "#         return(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cuw0quRMHtc4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkS8ZkvqIJoS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gc4ulF52FLI_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rm -rf logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ctTrYhJWRYQ8"
      },
      "cell_type": "markdown",
      "source": [
        "# Run it..."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KxR7xzEFMaPR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b79f87bd-e747-4ae5-9e58-87602bcdbdf4"
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "!if [ -f ngrok ] ; then echo \"Ngrok already installed\" ; else wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1 && unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1 ; fi\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ngrok already installed\n",
            "Tensorboard Link: https://7ff2aa90.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2W2kijdBpcyV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "57f637ea-d63b-4771-d261-7d539f4d05bb"
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "log_freq=20\n",
        "\n",
        "\n",
        "learning_rate = 0.0003\n",
        "# BiggerCNN_No_Dropout, .0005 seems to be best so far\n",
        "for cnn in [BiggerCNN_No_Dropout, BiggerCNN]:\n",
        "    for learning_rate in [.0005, .0003, .0001]:\n",
        "        net = cnn(batch_size=BATCH_SIZE)\n",
        "\n",
        "        # print a summary of the net statistics\n",
        "#         summary(net.to(device), (BATCH_SIZE*32, 3, 25, 25))\n",
        "\n",
        "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "        log_dir = f'./logs/{net.name}_lr{learning_rate}'\n",
        "        criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "\n",
        "\n",
        "    #     images, labels, original_imgs = next(iter(train_loader))\n",
        "    #     y = net.to(device)(Variable(images.to(device)))\n",
        "    #     make_dot(y)\n",
        "        # Run the model\n",
        "        model = train_model(net,\n",
        "                        log_dir,\n",
        "                        train_loader,\n",
        "                        criterion,\n",
        "                        optimizer,\n",
        "                        num_epochs, \n",
        "                        log_freq,\n",
        "                        print_guess=False) # or print_guess=true for pics\n",
        "        #                 print_guess=True) # or print_guess=False for tqdm\n",
        "        del(model)\n",
        "        del(criterion)\n",
        "        del(optimizer)\n",
        "\n",
        "        # final_acc = test_model(model, criterion, test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch 0:   0%|          | 0/1000 [00:00<?, ? minibatches/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training model. Logging to: \"./logs/BiggerCNN_No_Dropout_lr0.0005 (4397731.0)/\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 1000/1000 [05:36<00:00,  3.28 minibatches/s, loss=0.00826, training_accuracy=0.997]\n",
            "Epoch 0:   0%|          | 0/1000 [00:00<?, ? minibatches/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0: Training loss: 0.057539382918541375\n",
            "0: Training accuracy: 0.996874988079071\n",
            "Training model. Logging to: \"./logs/BiggerCNN_No_Dropout_lr0.0003 (4398068.0)/\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 1000/1000 [05:35<00:00,  3.32 minibatches/s, loss=0.00204, training_accuracy=1]\n",
            "Epoch 0:   0%|          | 0/1000 [00:00<?, ? minibatches/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0: Training loss: 0.06717007427624776\n",
            "0: Training accuracy: 1.0\n",
            "Training model. Logging to: \"./logs/BiggerCNN_No_Dropout_lr0.0001 (4398403.0)/\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 1000/1000 [05:34<00:00,  3.25 minibatches/s, loss=0.00611, training_accuracy=1]\n",
            "Epoch 0:   0%|          | 0/1000 [00:00<?, ? minibatches/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0: Training loss: 0.13112968915840612\n",
            "0: Training accuracy: 1.0\n",
            "Training model. Logging to: \"./logs/BiggerCNN_lr0.0005 (4398737.0)/\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 1000/1000 [05:37<00:00,  3.30 minibatches/s, loss=0.00433, training_accuracy=0.998]\n",
            "Epoch 0:   0%|          | 0/1000 [00:00<?, ? minibatches/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0: Training loss: 0.05776149991646525\n",
            "0: Training accuracy: 0.9984375238418579\n",
            "Training model. Logging to: \"./logs/BiggerCNN_lr0.0003 (4399075.0)/\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:  10%|█         | 101/1000 [00:34<04:38,  3.22 minibatches/s, loss=0.226, training_accuracy=0.93]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "jmtx5FYnIIvB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-3x1V0ClK9ZI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}