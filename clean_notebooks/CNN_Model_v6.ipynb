{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Model_v6.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "Yk33mywbpcxd"
      },
      "cell_type": "markdown",
      "source": [
        "# PyTorch Model on Dummy Dataset (v6)\n",
        "\n",
        "#### Chess Board Object Detection\n",
        "\n",
        "#### CIS 520, Spring 2019\n",
        "\n",
        "This notebook is written to run on [Google Colab](https://colab.research.google.com/notebook). \n",
        "\n",
        "----\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2JLf_jcWAi26",
        "outputId": "7d79320b-6913-4344-c9ed-848df6725c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "# # Check out available CPU and GPU memory\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "def print_CPU_GPU_info(GPUs):\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(f\"\\nCPU \\tRAM Free: {humanize.naturalsize(psutil.virtual_memory().available)}\"\n",
        "          f\"    | Proc size: {humanize.naturalsize(process.memory_info().rss)}\")\n",
        "    if GPUs[0]: \n",
        "        for i,gpu in enumerate(GPUs):\n",
        "            print(f\"GPU {i} \\tRAM Free: {gpu.memoryFree/1000:.3f} GB  \"\n",
        "                  f\"| Used: {gpu.memoryUsed/1000:.3f} GB\"\n",
        "                  f\"\\t| Utilization: {gpu.memoryUtil*100:3.0f}% | \"\n",
        "                  f\"Total Memory: {gpu.memoryTotal/1000:.3f} GB\")\n",
        "    else: print(f\"Not on a GPU\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tl7BZKJuOQ4t",
        "outputId": "83326dfb-7023-42a1-918e-556026249eea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print_CPU_GPU_info(GPU.getGPUs())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU \tRAM Free: 12.9 GB    | Proc size: 143.0 MB\n",
            "GPU 0 \tRAM Free: 11.441 GB  | Used: 0.000 GB\t| Utilization:   0% | Total Memory: 11.441 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OgjeP1M8pcxe",
        "outputId": "34945e55-729a-4de6-9cea-280b0488c4e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "cell_type": "code",
      "source": [
        "%%javascript\n",
        "IPython.OutputArea.prototype._should_scroll = function(lines) { return false; }\n",
        "// disable scrollable cells"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.OutputArea.prototype._should_scroll = function(lines) { return false; }\n",
              "// disable scrollable cells"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "c6f5WavtHSJb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # ! rm -rf pytorch_general\n",
        "# # ! rm pytorch_general\n",
        "# # ! rm -rf images\n",
        "# # ! rm -rf piece_images\n",
        "# ! rm -rf chess-ray-vision\n",
        "# ! rm -rf utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iX8Q9D1Fpcxj",
        "outputId": "65279d05-15fe-4c3f-8c6e-f4b1460e243a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/samryan18/chess-ray-vision\n",
        "! mv chess-ray-vision/clean_notebooks/* .\n",
        "\n",
        "\n",
        "#NOTE this next line will download 2+ GB of data\n",
        "#Do not run locally unless your comp can take that kinda heat\n",
        "! git clone https://github.com/mukundv7/crvdataset \n",
        "! mkdir train_full\n",
        "! mv crvdataset/chess-positions/train-full/* train_full/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'chess-ray-vision'...\n",
            "remote: Enumerating objects: 165, done.\u001b[K\n",
            "remote: Counting objects: 100% (165/165), done.\u001b[K\n",
            "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "remote: Total 165 (delta 67), reused 130 (delta 32), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (165/165), 42.29 MiB | 33.86 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n",
            "Cloning into 'crvdataset'...\n",
            "remote: Enumerating objects: 39509, done.\u001b[K\n",
            "remote: Counting objects: 100% (39509/39509), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39378/39378), done.\u001b[K\n",
            "remote: Total 39509 (delta 150), reused 39484 (delta 128), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (39509/39509), 770.54 MiB | 29.85 MiB/s, done.\n",
            "Resolving deltas: 100% (150/150), done.\n",
            "Checking out files: 100% (39691/39691), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "rVc5YZiHpcxl"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup Stuff"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "G5YloGGWqY72",
        "outputId": "ecade99d-65f5-4069-8166-3d94af540680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "# Pytorch Colab Setup\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "  \n",
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.0.1 from https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl (614.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 614.8MB 30kB/s \n",
            "\u001b[31mfastai 1.0.50.post1 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.0.1.post2\n",
            "    Uninstalling torch-1.0.1.post2:\n",
            "      Successfully uninstalled torch-1.0.1.post2\n",
            "Successfully installed torch-1.0.1\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "joxmigYl9iK9",
        "outputId": "aca2058a-e027-44df-9607-3e66b72ee19a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "cell_type": "code",
      "source": [
        "## Required packages (Install in Colab)\n",
        "!pip install tensorflow\n",
        "!pip install scipy\n",
        "!pip install numpy\n",
        "!pip install Pillow\n",
        "!pip install image\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.8.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.1)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.14.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n",
            "Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.1.7)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.1.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.9)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wkGhAHeKpcxx",
        "outputId": "b4384c4f-900e-4dee-dd44-903be5858886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "####################################################\n",
        "# CODE IMPORTS\n",
        "\n",
        "from pytorch_general.pytorch_helper import imshow\n",
        "from pytorch_general.tensorboard_helper import Logger\n",
        "from utils.data_loading_utils import (onehot_from_fen, fen_from_onehot, \n",
        "                                     fen_from_64, fen_from_filename, \n",
        "                                     process_image)\n",
        "from utils.draw_chess_boards import DrawChessPosition\n",
        "\n",
        "####################################################\n",
        "# EXTERNAL IMPORTS\n",
        "\n",
        "import torchvision\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import numpy as np;\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time, datetime\n",
        "from tqdm import tqdm\n",
        "from torchsummary import summary\n",
        "\n",
        "from random import randint\n",
        "\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from random import shuffle\n",
        "import os\n",
        "\n",
        "\n",
        "import glob\n",
        "\n",
        "import torch.optim as optim\n",
        "device =torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OIq7Yn4mpmoD",
        "outputId": "3bb00c20-52f1-407d-a22e-82618fbc5063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "fen = '4kN1N-bbbbbbbb-QQ3B2-R1n1b3-8-8-ppqKbKbk-8'\n",
        "class_prob = onehot_from_fen(fen)\n",
        "\n",
        "print(f\"Original: \\t{fen}\")\n",
        "print(f\"Reconstructed:  {fen_from_onehot(class_prob)}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: \t4kN1N-bbbbbbbb-QQ3B2-R1n1b3-8-8-ppqKbKbk-8\n",
            "Reconstructed:  4kN1N-bbbbbbbb-QQ3B2-R1n1b3-8-8-ppqKbKbk-8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jprHKvxU8D0M",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CustomChessDataset(Dataset):\n",
        "    \"\"\"Chess dataset\"\"\"\n",
        "\n",
        "    def __init__(self, \n",
        "                 transform=None,\n",
        "                 root='train_full',\n",
        "                 train_size = 10000,\n",
        "                 test_size = 3000,\n",
        "                 downsample_size = 200,\n",
        "                 train=True):\n",
        "\n",
        "        self._train = train\n",
        "        self.downsample_size = downsample_size\n",
        "            \n",
        "        self.root = root\n",
        "        self.pathlist = list(Path(self.root).glob('**/*.jpeg'))\n",
        "        self.n_files = len(self.pathlist)\n",
        "        \n",
        "        self.train_size = train_size\n",
        "        self.test_size = test_size\n",
        "\n",
        "        self.train = glob.glob(f\"{root}/*.jpeg\")\n",
        "        self.test = glob.glob(f\"{root}/*.jpeg\")\n",
        "\n",
        "        shuffle(self.train)\n",
        "        shuffle(self.test)\n",
        "\n",
        "        self.train = self.train[:self.train_size]\n",
        "        self.test = self.test[:self.test_size]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.train_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.train[idx]\n",
        "        label = onehot_from_fen(fen_from_filename(img))\n",
        "        img_as_img, original_img = process_image(img, \n",
        "                                                 downsample_size = self.downsample_size)\n",
        "\n",
        "        return ((torch.from_numpy(img_as_img).float()), \n",
        "                label,\n",
        "                original_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eyai4agLpcyB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# BATCH_SIZE needs to be small ish bc bigger models will scale \n",
        "# memory usage exponentially\n",
        "BATCH_SIZE=10 \n",
        "downsample_size=200\n",
        "transform = transforms.Compose([transforms.Resize(downsample_size)])\n",
        "\n",
        "train_dataset = CustomChessDataset(root='train_full/', train=True, \n",
        "                                   downsample_size=downsample_size)\n",
        "test_dataset = CustomChessDataset(root='train_full/', train=False, \n",
        "                                  downsample_size=downsample_size)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L84LWc3jpcyL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model: nn.Module, \n",
        "                log_dir: str,\n",
        "                train_loader: torch.utils.data.DataLoader,\n",
        "                criterion: torch.nn.modules.Module,\n",
        "                optimizer: torch.optim.Optimizer,\n",
        "                num_epochs: int=1,\n",
        "                log_freq: int=25,\n",
        "                print_guess=False,\n",
        "                print_guess_freq=50) -> nn.Module:\n",
        "    \n",
        "    # Create Logging Directory for Tensorboard\n",
        "    now = time.mktime(datetime.datetime.now().timetuple()) - 1550000000\n",
        "    log_dir = f'{log_dir} ({now})/'\n",
        "    logger = Logger(log_dir)\n",
        "    print(f'Training model. Logging to: \"{log_dir}\"\\n')\n",
        "\n",
        "    model = model.to(device) # Send model to GPU if possible\n",
        "    model.train() # Set model to training mode\n",
        "\n",
        "    total_step = len(train_loader)\n",
        "    for epoch in range(num_epochs):\n",
        "        if print_guess: print(f'Epoch {epoch}')\n",
        "        running_loss = 0\n",
        "        \n",
        "        # Tqdm will create a progress bar\n",
        "        with tqdm(total=len(train_loader), \n",
        "                  desc=f'Epoch {epoch}', \n",
        "                  unit=' minibatches',\n",
        "                  disable=(print_guess)) as pbar:\n",
        "            \n",
        "            # Iterate through minibatches\n",
        "            for step, (images, labels, original_imgs) in enumerate(train_loader):\n",
        "                images, labels = images.to(device), labels.long().to(device)\n",
        "\n",
        "                output = model(images).to(device)\n",
        "                _,class_labels = torch.max(labels,2) \n",
        "                _, argmax = torch.max(output, 2)\n",
        "\n",
        "                accuracy = float((class_labels == \n",
        "                                  argmax.squeeze()).float().mean().cpu())\n",
        "\n",
        "                loss = criterion(output.reshape(10*64,13).float(),\n",
        "                                 class_labels.reshape(10*64))\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "\n",
        "                running_loss += float(loss.item())\n",
        "                \n",
        "                pbar.set_postfix(training_accuracy=accuracy, loss=loss.item(), refresh=True)\n",
        "                pbar.update(1)\n",
        "                \n",
        "                if step % log_freq == 0:\n",
        "                    overall_step = epoch*total_step + step\n",
        "\n",
        "                    # 1. Log scalar values (scalar summary)\n",
        "                    info = { 'loss': loss.item(), 'accuracy': accuracy }\n",
        "\n",
        "                    for key, value in info.items():\n",
        "                        logger.scalar_summary(key, value, overall_step)\n",
        "\n",
        "                    # 2. Log values and gradients of the parameters\n",
        "                    # (histogram summary)\n",
        "                    for key, value in model.named_parameters():\n",
        "                        key = key.replace('.', '/')\n",
        "                        logger.histo_summary(key, \n",
        "                                             value.data.cpu().numpy(), \n",
        "                                             overall_step)\n",
        "                        try:\n",
        "                            logger.histo_summary(key+'/grad', \n",
        "                                                 value.grad.data.cpu().numpy(),\n",
        "                                                 overall_step)\n",
        "                        except (AttributeError):\n",
        "                            # During transfer learning some of the variables \n",
        "                            # don't have grads\n",
        "                            pass\n",
        "    \n",
        "                if print_guess and step % print_guess_freq == 0:\n",
        "\n",
        "                    overall_step = epoch*total_step + step\n",
        "                    print(f\"\\n{60*'-'}\\nBatch Number: {overall_step}\")\n",
        "                    print(f\"Example training point:\")\n",
        "                    print(f\"Actual: {fen_from_64(class_labels.cpu()[0])}\")\n",
        "                    print(f\"Guess: {fen_from_64(argmax.cpu()[0])}\")\n",
        "                    print(f\"Example Accuracy: {float((class_labels[0] == argmax[0]).float().mean().cpu())}\")\n",
        "                    \n",
        "                    renderer = DrawChessPosition(delimiter='-')\n",
        "                    board_actual = renderer.draw(fen_from_64(class_labels.cpu()[0]))\n",
        "                    board_guess = renderer.draw(fen_from_64(argmax.cpu()[0]))\n",
        "                    renderer.show_side_by_side(board1= original_imgs[0],\n",
        "                                               board2=board_guess, \n",
        "                                               board1_title='Actual',\n",
        "                                               board2_title='Prediction (Re'\n",
        "                                                            'ndered to image)')\n",
        "        print(f\"{epoch}: Training loss: {running_loss/len(train_loader)}\")\n",
        "        print(f\"{epoch}: Training accuracy: {accuracy}\")\n",
        " \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def test_model(model, criterion, test_loader) -> float:\n",
        "    \n",
        "    '''\n",
        "    TODO: REWRITE THIS\n",
        "    '''\n",
        "    model = model.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    accuracies = []\n",
        "    losses = []\n",
        "    total_step = len(test_loader)\n",
        "    with torch.no_grad():\n",
        "        for i in range(total_step):\n",
        "            for  images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.long().to(device)\n",
        "                _,class_labels = torch.max(labels,1) \n",
        "\n",
        "                output = model(images).to(device)\n",
        "                loss = criterion(output, class_labels)\n",
        "                losses.append(float(loss.item()))\n",
        "\n",
        "\n",
        "                # Compute accuracy\n",
        "                _, argmax = torch.max(output, 1)\n",
        "                accuracy = float((class_labels == argmax.squeeze()).float().mean().cpu())\n",
        "                accuracies.append(accuracy)\n",
        "                \n",
        "    print(f'Accuracy of the network on test images: {np.average(accuracies)}')\n",
        "    print(f'Avg. Loss of the network on test images: {np.average(losses)}')\n",
        "\n",
        "    return np.average(accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LC5DpAfNRVUL"
      },
      "cell_type": "markdown",
      "source": [
        "# Models"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HRQAmGX57yo0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1) \n",
        "\n",
        "class SimpleCNN(torch.nn.Module):\n",
        "    def __init__(self, batch_size):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.name = 'SimpleCNN'\n",
        "        self.batch_size=batch_size\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1),\n",
        "            nn.LeakyReLU(negative_slope=0.1))\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1),\n",
        "            nn.ReLU())\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1),\n",
        "            nn.ReLU())\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(32*19*19, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.1))\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(256, 13))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(self.batch_size*64,3,25,25)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        \n",
        "        x = self.flatten(x)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "#         print(f'xsize: {x.size()}')\n",
        "        x = x.reshape(self.batch_size,64,13)\n",
        "\n",
        "        return(x)\n",
        "    \n",
        "class BiggerCNN(torch.nn.Module):\n",
        "    def __init__(self, batch_size):\n",
        "        super(BiggerCNN, self).__init__()\n",
        "        self.name = 'BiggerCNN'\n",
        "        self.batch_size=batch_size\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.LeakyReLU(negative_slope=0.1))\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.ReLU())\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.ReLU())\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(64*19*19, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.1))\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.1))\n",
        "        self.fc3 = nn.Sequential(\n",
        "            nn.Linear(256, 13))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(self.batch_size*64,3,25,25)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        \n",
        "        x = self.flatten(x)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "#         print(f'xsize: {x.size()}')\n",
        "        x = x.reshape(self.batch_size,64,13)\n",
        "\n",
        "        return(x)\n",
        "    \n",
        "# class BatchNormBiggerCNN(torch.nn.Module):\n",
        "#     def __init__(self, batch_size):\n",
        "#         super(BatchNormBiggerCNN, self).__init__()\n",
        "#         self.name = 'BatchNormBiggerCNN'\n",
        "#         self.batch_size=batch_size\n",
        "#         self.conv1 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1),\n",
        "#             nn.BatchNorm2d(64),\n",
        "#             nn.LeakyReLU(negative_slope=0.1),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.conv2 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "#             nn.BatchNorm2d(64),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.conv3 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "#             nn.ReLU())\n",
        "#         self.flatten = Flatten()\n",
        "#         self.fc1 = nn.Sequential(\n",
        "#             nn.Linear(64*19*19, 512),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.fc2 = nn.Sequential(\n",
        "#             nn.Linear(512, 256),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.fc3 = nn.Sequential(\n",
        "#             nn.Linear(256, 13))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = x.reshape(self.batch_size*64,3,25,25)\n",
        "\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.conv2(x)\n",
        "#         x = self.conv3(x)\n",
        "        \n",
        "#         x = self.flatten(x)\n",
        "        \n",
        "#         x = self.fc1(x)\n",
        "#         x = self.fc2(x)\n",
        "#         x = self.fc3(x)\n",
        "\n",
        "# #         print(f'xsize: {x.size()}')\n",
        "#         x = x.reshape(self.batch_size,64,13)\n",
        "\n",
        "#         return(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cuw0quRMHtc4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "0e3fa57d-d2ea-4346-e8c7-efeb2a818df6"
      },
      "cell_type": "code",
      "source": [
        "pip install torchviz\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.0.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vkS8ZkvqIJoS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gc4ulF52FLI_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ctTrYhJWRYQ8"
      },
      "cell_type": "markdown",
      "source": [
        "# Run it..."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KxR7xzEFMaPR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "!if [ -f ngrok ] ; then echo \"Ngrok already installed\" ; else wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1 && unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1 ; fi\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2W2kijdBpcyV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1632
        },
        "outputId": "dee89ef8-162b-436e-ae4e-b49a6d54acd3"
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "log_freq=20\n",
        "\n",
        "\n",
        "learning_rate = 0.0003\n",
        "    \n",
        "net = BiggerCNN(batch_size=BATCH_SIZE)\n",
        "\n",
        "# print a summary of the net statistics\n",
        "summary(net.to(device), (BATCH_SIZE*32, 3, 25, 25))\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "log_dir = f'./logs/{net.name}_lr{learning_rate}'\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "\n",
        "\n",
        "images, labels, original_imgs = next(iter(train_loader))\n",
        "y = net.to(device)(Variable(images.to(device)))\n",
        "make_dot(y)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 23, 23]           1,792\n",
            "         LeakyReLU-2           [-1, 64, 23, 23]               0\n",
            "            Conv2d-3           [-1, 64, 21, 21]          36,928\n",
            "              ReLU-4           [-1, 64, 21, 21]               0\n",
            "            Conv2d-5           [-1, 64, 19, 19]          36,928\n",
            "              ReLU-6           [-1, 64, 19, 19]               0\n",
            "           Flatten-7                [-1, 23104]               0\n",
            "            Linear-8                  [-1, 512]      11,829,760\n",
            "              ReLU-9                  [-1, 512]               0\n",
            "          Dropout-10                  [-1, 512]               0\n",
            "           Linear-11                  [-1, 256]         131,328\n",
            "             ReLU-12                  [-1, 256]               0\n",
            "          Dropout-13                  [-1, 256]               0\n",
            "           Linear-14                   [-1, 13]           3,341\n",
            "================================================================\n",
            "Total params: 12,040,077\n",
            "Trainable params: 12,040,077\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 2.29\n",
            "Forward/backward pass size (MB): 1.49\n",
            "Params size (MB): 45.93\n",
            "Estimated Total Size (MB): 49.71\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fba41ed9080>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"417pt\" height=\"864pt\"\n viewBox=\"0.00 0.00 417.46 864.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(.8554 .8554) rotate(0) translate(4 1006)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-1006 484,-1006 484,4 -4,4\"/>\n<!-- 140437946733848 -->\n<g id=\"node1\" class=\"node\">\n<title>140437946733848</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"378,-21 265,-21 265,0 378,0 378,-21\"/>\n<text text-anchor=\"middle\" x=\"321.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AsStridedBackward</text>\n</g>\n<!-- 140437946732840 -->\n<g id=\"node2\" class=\"node\">\n<title>140437946732840</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"373.5,-78 269.5,-78 269.5,-57 373.5,-57 373.5,-78\"/>\n<text text-anchor=\"middle\" x=\"321.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 140437946732840&#45;&gt;140437946733848 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140437946732840&#45;&gt;140437946733848</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M321.5,-56.7787C321.5,-49.6134 321.5,-39.9517 321.5,-31.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"325.0001,-31.1732 321.5,-21.1732 318.0001,-31.1732 325.0001,-31.1732\"/>\n</g>\n<!-- 140437946733008 -->\n<g id=\"node3\" class=\"node\">\n<title>140437946733008</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"236.5,-149 182.5,-149 182.5,-114 236.5,-114 236.5,-149\"/>\n<text text-anchor=\"middle\" x=\"209.5\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (13)</text>\n</g>\n<!-- 140437946733008&#45;&gt;140437946732840 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140437946733008&#45;&gt;140437946732840</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M236.6121,-116.0074C253.9825,-106.0814 276.4595,-93.2374 293.9206,-83.2597\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"296.0948,-86.0484 303.0408,-78.0481 292.6218,-79.9707 296.0948,-86.0484\"/>\n</g>\n<!-- 140437946733176 -->\n<g id=\"node4\" class=\"node\">\n<title>140437946733176</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"388.5,-142 254.5,-142 254.5,-121 388.5,-121 388.5,-142\"/>\n<text text-anchor=\"middle\" x=\"321.5\" y=\"-128.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">FusedDropoutBackward</text>\n</g>\n<!-- 140437946733176&#45;&gt;140437946732840 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140437946733176&#45;&gt;140437946732840</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M321.5,-120.9317C321.5,-112.0913 321.5,-99.2122 321.5,-88.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"325.0001,-88.2979 321.5,-78.2979 318.0001,-88.2979 325.0001,-88.2979\"/>\n</g>\n<!-- 140437946733232 -->\n<g id=\"node5\" class=\"node\">\n<title>140437946733232</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"381,-213 262,-213 262,-192 381,-192 381,-213\"/>\n<text text-anchor=\"middle\" x=\"321.5\" y=\"-199.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ThresholdBackward0</text>\n</g>\n<!-- 140437946733232&#45;&gt;140437946733176 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140437946733232&#45;&gt;140437946733176</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M321.5,-191.7166C321.5,-181.3953 321.5,-165.5401 321.5,-152.6896\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"325.0001,-152.3848 321.5,-142.3849 318.0001,-152.3849 325.0001,-152.3848\"/>\n</g>\n<!-- 140437946733624 -->\n<g id=\"node6\" class=\"node\">\n<title>140437946733624</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"373.5,-277 269.5,-277 269.5,-256 373.5,-256 373.5,-277\"/>\n<text text-anchor=\"middle\" x=\"321.5\" y=\"-263.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 140437946733624&#45;&gt;140437946733232 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140437946733624&#45;&gt;140437946733232</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M321.5,-255.9317C321.5,-247.0913 321.5,-234.2122 321.5,-223.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"325.0001,-223.2979 321.5,-213.2979 318.0001,-223.2979 325.0001,-223.2979\"/>\n</g>\n<!-- 140437946733344 -->\n<g id=\"node7\" class=\"node\">\n<title>140437946733344</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"236.5,-348 182.5,-348 182.5,-313 236.5,-313 236.5,-348\"/>\n<text text-anchor=\"middle\" x=\"209.5\" y=\"-320.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256)</text>\n</g>\n<!-- 140437946733344&#45;&gt;140437946733624 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140437946733344&#45;&gt;140437946733624</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M236.6121,-315.0074C253.9825,-305.0814 276.4595,-292.2374 293.9206,-282.2597\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"296.0948,-285.0484 303.0408,-277.0481 292.6218,-278.9707 296.0948,-285.0484\"/>\n</g>\n<!-- 140437946733120 -->\n<g id=\"node8\" class=\"node\">\n<title>140437946733120</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"388.5,-341 254.5,-341 254.5,-320 388.5,-320 388.5,-341\"/>\n<text text-anchor=\"middle\" x=\"321.5\" y=\"-327.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">FusedDropoutBackward</text>\n</g>\n<!-- 140437946733120&#45;&gt;140437946733624 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140437946733120&#45;&gt;140437946733624</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M321.5,-319.9317C321.5,-311.0913 321.5,-298.2122 321.5,-287.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"325.0001,-287.2979 321.5,-277.2979 318.0001,-287.2979 325.0001,-287.2979\"/>\n</g>\n<!-- 140437946733904 -->\n<g id=\"node9\" class=\"node\">\n<title>140437946733904</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"381,-412 262,-412 262,-391 381,-391 381,-412\"/>\n<text text-anchor=\"middle\" x=\"321.5\" y=\"-398.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ThresholdBackward0</text>\n</g>\n<!-- 140437946733904&#45;&gt;140437946733120 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140437946733904&#45;&gt;140437946733120</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M321.5,-390.7166C321.5,-380.3953 321.5,-364.5401 321.5,-351.6896\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"325.0001,-351.3848 321.5,-341.3849 318.0001,-351.3849 325.0001,-351.3848\"/>\n</g>\n<!-- 140437946733512 -->\n<g id=\"node10\" class=\"node\">\n<title>140437946733512</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"373.5,-476 269.5,-476 269.5,-455 373.5,-455 373.5,-476\"/>\n<text text-anchor=\"middle\" x=\"321.5\" y=\"-462.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 140437946733512&#45;&gt;140437946733904 -->\n<g id=\"edge9\" class=\"edge\">\n<title>140437946733512&#45;&gt;140437946733904</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M321.5,-454.9317C321.5,-446.0913 321.5,-433.2122 321.5,-422.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"325.0001,-422.2979 321.5,-412.2979 318.0001,-422.2979 325.0001,-422.2979\"/>\n</g>\n<!-- 140437946733736 -->\n<g id=\"node11\" class=\"node\">\n<title>140437946733736</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"257.5,-547 203.5,-547 203.5,-512 257.5,-512 257.5,-547\"/>\n<text text-anchor=\"middle\" x=\"230.5\" y=\"-519.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (512)</text>\n</g>\n<!-- 140437946733736&#45;&gt;140437946733512 -->\n<g id=\"edge10\" class=\"edge\">\n<title>140437946733736&#45;&gt;140437946733512</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M255.8486,-511.6724C269.0947,-502.3565 285.1963,-491.0322 298.1383,-481.9302\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"300.3532,-484.6514 306.5194,-476.0358 296.3263,-478.9257 300.3532,-484.6514\"/>\n</g>\n<!-- 140437946733400 -->\n<g id=\"node12\" class=\"node\">\n<title>140437946733400</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"367,-540 276,-540 276,-519 367,-519 367,-540\"/>\n<text text-anchor=\"middle\" x=\"321.5\" y=\"-526.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ViewBackward</text>\n</g>\n<!-- 140437946733400&#45;&gt;140437946733512 -->\n<g id=\"edge11\" class=\"edge\">\n<title>140437946733400&#45;&gt;140437946733512</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M321.5,-518.9317C321.5,-510.0913 321.5,-497.2122 321.5,-486.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"325.0001,-486.2979 321.5,-476.2979 318.0001,-486.2979 325.0001,-486.2979\"/>\n</g>\n<!-- 140437937778640 -->\n<g id=\"node13\" class=\"node\">\n<title>140437937778640</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"377,-611 258,-611 258,-590 377,-590 377,-611\"/>\n<text text-anchor=\"middle\" x=\"317.5\" y=\"-597.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ThresholdBackward0</text>\n</g>\n<!-- 140437937778640&#45;&gt;140437946733400 -->\n<g id=\"edge12\" class=\"edge\">\n<title>140437937778640&#45;&gt;140437946733400</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M318.1075,-589.7166C318.689,-579.3953 319.5822,-563.5401 320.3062,-550.6896\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"323.8186,-550.5659 320.8868,-540.3849 316.8297,-550.1721 323.8186,-550.5659\"/>\n</g>\n<!-- 140437937778584 -->\n<g id=\"node14\" class=\"node\">\n<title>140437937778584</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"396,-675 239,-675 239,-654 396,-654 396,-675\"/>\n<text text-anchor=\"middle\" x=\"317.5\" y=\"-661.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n</g>\n<!-- 140437937778584&#45;&gt;140437937778640 -->\n<g id=\"edge13\" class=\"edge\">\n<title>140437937778584&#45;&gt;140437937778640</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M317.5,-653.9317C317.5,-645.0913 317.5,-632.2122 317.5,-621.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"321.0001,-621.2979 317.5,-611.2979 314.0001,-621.2979 321.0001,-621.2979\"/>\n</g>\n<!-- 140437937778360 -->\n<g id=\"node15\" class=\"node\">\n<title>140437937778360</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"259,-739 140,-739 140,-718 259,-718 259,-739\"/>\n<text text-anchor=\"middle\" x=\"199.5\" y=\"-725.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ThresholdBackward0</text>\n</g>\n<!-- 140437937778360&#45;&gt;140437937778584 -->\n<g id=\"edge14\" class=\"edge\">\n<title>140437937778360&#45;&gt;140437937778584</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M218.9853,-717.9317C238.0305,-707.6021 267.2422,-691.7585 288.9162,-680.0031\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"290.8641,-682.9283 297.9858,-675.084 287.5267,-676.7751 290.8641,-682.9283\"/>\n</g>\n<!-- 140437937664744 -->\n<g id=\"node16\" class=\"node\">\n<title>140437937664744</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"278,-803 121,-803 121,-782 278,-782 278,-803\"/>\n<text text-anchor=\"middle\" x=\"199.5\" y=\"-789.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n</g>\n<!-- 140437937664744&#45;&gt;140437937778360 -->\n<g id=\"edge15\" class=\"edge\">\n<title>140437937664744&#45;&gt;140437937778360</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M199.5,-781.9317C199.5,-773.0913 199.5,-760.2122 199.5,-749.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"203.0001,-749.2979 199.5,-739.2979 196.0001,-749.2979 203.0001,-749.2979\"/>\n</g>\n<!-- 140437937664296 -->\n<g id=\"node17\" class=\"node\">\n<title>140437937664296</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"140.5,-867 16.5,-867 16.5,-846 140.5,-846 140.5,-867\"/>\n<text text-anchor=\"middle\" x=\"78.5\" y=\"-853.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">LeakyReluBackward0</text>\n</g>\n<!-- 140437937664296&#45;&gt;140437937664744 -->\n<g id=\"edge16\" class=\"edge\">\n<title>140437937664296&#45;&gt;140437937664744</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M98.4807,-845.9317C118.0976,-835.5558 148.2333,-819.6163 170.488,-807.8452\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"172.2864,-810.8535 179.4896,-803.084 169.0135,-804.6657 172.2864,-810.8535\"/>\n</g>\n<!-- 140437937665136 -->\n<g id=\"node18\" class=\"node\">\n<title>140437937665136</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"157,-931 0,-931 0,-910 157,-910 157,-931\"/>\n<text text-anchor=\"middle\" x=\"78.5\" y=\"-917.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n</g>\n<!-- 140437937665136&#45;&gt;140437937664296 -->\n<g id=\"edge17\" class=\"edge\">\n<title>140437937665136&#45;&gt;140437937664296</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M78.5,-909.9317C78.5,-901.0913 78.5,-888.2122 78.5,-877.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"82.0001,-877.2979 78.5,-867.2979 75.0001,-877.2979 82.0001,-877.2979\"/>\n</g>\n<!-- 140437937665304 -->\n<g id=\"node19\" class=\"node\">\n<title>140437937665304</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"75,-1002 0,-1002 0,-967 75,-967 75,-1002\"/>\n<text text-anchor=\"middle\" x=\"37.5\" y=\"-974.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64, 3, 3, 3)</text>\n</g>\n<!-- 140437937665304&#45;&gt;140437937665136 -->\n<g id=\"edge18\" class=\"edge\">\n<title>140437937665304&#45;&gt;140437937665136</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M48.9208,-966.6724C54.2802,-958.3066 60.6771,-948.3212 66.1488,-939.7799\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"69.1831,-941.5318 71.6303,-931.2234 63.2889,-937.7558 69.1831,-941.5318\"/>\n</g>\n<!-- 140437937665416 -->\n<g id=\"node20\" class=\"node\">\n<title>140437937665416</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"147.5,-1002 93.5,-1002 93.5,-967 147.5,-967 147.5,-1002\"/>\n<text text-anchor=\"middle\" x=\"120.5\" y=\"-974.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64)</text>\n</g>\n<!-- 140437937665416&#45;&gt;140437937665136 -->\n<g id=\"edge19\" class=\"edge\">\n<title>140437937665416&#45;&gt;140437937665136</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M108.8007,-966.6724C103.3105,-958.3066 96.7576,-948.3212 91.1524,-939.7799\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"93.95,-937.6636 85.5373,-931.2234 88.0977,-941.5042 93.95,-937.6636\"/>\n</g>\n<!-- 140437937665192 -->\n<g id=\"node21\" class=\"node\">\n<title>140437937665192</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"240,-874 159,-874 159,-839 240,-839 240,-874\"/>\n<text text-anchor=\"middle\" x=\"199.5\" y=\"-846.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64, 64, 3, 3)</text>\n</g>\n<!-- 140437937665192&#45;&gt;140437937664744 -->\n<g id=\"edge20\" class=\"edge\">\n<title>140437937665192&#45;&gt;140437937664744</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M199.5,-838.6724C199.5,-830.8405 199.5,-821.5893 199.5,-813.4323\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"203.0001,-813.2234 199.5,-803.2234 196.0001,-813.2235 203.0001,-813.2234\"/>\n</g>\n<!-- 140437937664912 -->\n<g id=\"node22\" class=\"node\">\n<title>140437937664912</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"312.5,-874 258.5,-874 258.5,-839 312.5,-839 312.5,-874\"/>\n<text text-anchor=\"middle\" x=\"285.5\" y=\"-846.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64)</text>\n</g>\n<!-- 140437937664912&#45;&gt;140437937664744 -->\n<g id=\"edge21\" class=\"edge\">\n<title>140437937664912&#45;&gt;140437937664744</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M261.5442,-838.6724C249.1462,-829.446 234.1013,-818.2498 221.9317,-809.1934\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"223.7694,-806.1981 213.6575,-803.0358 219.5903,-811.8138 223.7694,-806.1981\"/>\n</g>\n<!-- 140437937778528 -->\n<g id=\"node23\" class=\"node\">\n<title>140437937778528</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"358,-746 277,-746 277,-711 358,-711 358,-746\"/>\n<text text-anchor=\"middle\" x=\"317.5\" y=\"-718.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64, 64, 3, 3)</text>\n</g>\n<!-- 140437937778528&#45;&gt;140437937778584 -->\n<g id=\"edge22\" class=\"edge\">\n<title>140437937778528&#45;&gt;140437937778584</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M317.5,-710.6724C317.5,-702.8405 317.5,-693.5893 317.5,-685.4323\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"321.0001,-685.2234 317.5,-675.2234 314.0001,-685.2235 321.0001,-685.2234\"/>\n</g>\n<!-- 140437937664856 -->\n<g id=\"node24\" class=\"node\">\n<title>140437937664856</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"430.5,-746 376.5,-746 376.5,-711 430.5,-711 430.5,-746\"/>\n<text text-anchor=\"middle\" x=\"403.5\" y=\"-718.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64)</text>\n</g>\n<!-- 140437937664856&#45;&gt;140437937778584 -->\n<g id=\"edge23\" class=\"edge\">\n<title>140437937664856&#45;&gt;140437937778584</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M379.5442,-710.6724C367.1462,-701.446 352.1013,-690.2498 339.9317,-681.1934\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"341.7694,-678.1981 331.6575,-675.0358 337.5903,-683.8138 341.7694,-678.1981\"/>\n</g>\n<!-- 140437946733680 -->\n<g id=\"node25\" class=\"node\">\n<title>140437946733680</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"467,-540 394,-540 394,-519 467,-519 467,-540\"/>\n<text text-anchor=\"middle\" x=\"430.5\" y=\"-526.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 140437946733680&#45;&gt;140437946733512 -->\n<g id=\"edge24\" class=\"edge\">\n<title>140437946733680&#45;&gt;140437946733512</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M412.5009,-518.9317C394.9872,-508.6484 368.1664,-492.9005 348.1734,-481.1615\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"349.9215,-478.1291 339.5259,-476.084 346.3771,-484.1655 349.9215,-478.1291\"/>\n</g>\n<!-- 140437937778472 -->\n<g id=\"node26\" class=\"node\">\n<title>140437937778472</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"476,-618 395,-618 395,-583 476,-583 476,-618\"/>\n<text text-anchor=\"middle\" x=\"435.5\" y=\"-590.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (512, 23104)</text>\n</g>\n<!-- 140437937778472&#45;&gt;140437946733680 -->\n<g id=\"edge25\" class=\"edge\">\n<title>140437937778472&#45;&gt;140437946733680</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M434.264,-582.9494C433.5675,-573.058 432.6932,-560.6435 431.9626,-550.2693\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"435.4354,-549.7582 431.2415,-540.0288 428.4527,-550.25 435.4354,-549.7582\"/>\n</g>\n<!-- 140437946734072 -->\n<g id=\"node27\" class=\"node\">\n<title>140437946734072</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"480,-341 407,-341 407,-320 480,-320 480,-341\"/>\n<text text-anchor=\"middle\" x=\"443.5\" y=\"-327.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 140437946734072&#45;&gt;140437946733624 -->\n<g id=\"edge26\" class=\"edge\">\n<title>140437946734072&#45;&gt;140437946733624</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M423.3542,-319.9317C403.5751,-309.5558 373.1904,-293.6163 350.7517,-281.8452\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"352.1572,-278.6301 341.6757,-277.084 348.9053,-284.829 352.1572,-278.6301\"/>\n</g>\n<!-- 140437946733568 -->\n<g id=\"node28\" class=\"node\">\n<title>140437946733568</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"478,-419 409,-419 409,-384 478,-384 478,-419\"/>\n<text text-anchor=\"middle\" x=\"443.5\" y=\"-391.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256, 512)</text>\n</g>\n<!-- 140437946733568&#45;&gt;140437946734072 -->\n<g id=\"edge27\" class=\"edge\">\n<title>140437946733568&#45;&gt;140437946734072</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M443.5,-383.9494C443.5,-374.058 443.5,-361.6435 443.5,-351.2693\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"447.0001,-351.0288 443.5,-341.0288 440.0001,-351.0289 447.0001,-351.0288\"/>\n</g>\n<!-- 140437946733064 -->\n<g id=\"node29\" class=\"node\">\n<title>140437946733064</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"480,-142 407,-142 407,-121 480,-121 480,-142\"/>\n<text text-anchor=\"middle\" x=\"443.5\" y=\"-128.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 140437946733064&#45;&gt;140437946732840 -->\n<g id=\"edge28\" class=\"edge\">\n<title>140437946733064&#45;&gt;140437946732840</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M423.3542,-120.9317C403.5751,-110.5558 373.1904,-94.6163 350.7517,-82.8452\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"352.1572,-79.6301 341.6757,-78.084 348.9053,-85.829 352.1572,-79.6301\"/>\n</g>\n<!-- 140437946732896 -->\n<g id=\"node30\" class=\"node\">\n<title>140437946732896</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"475,-220 412,-220 412,-185 475,-185 475,-220\"/>\n<text text-anchor=\"middle\" x=\"443.5\" y=\"-192.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (13, 256)</text>\n</g>\n<!-- 140437946732896&#45;&gt;140437946733064 -->\n<g id=\"edge29\" class=\"edge\">\n<title>140437946732896&#45;&gt;140437946733064</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M443.5,-184.9494C443.5,-175.058 443.5,-162.6435 443.5,-152.2693\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"447.0001,-152.0288 443.5,-142.0288 440.0001,-152.0289 447.0001,-152.0288\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "FmYwcUJgJXTg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fed91b94-476f-4b2e-ad68-3634cecd37ee"
      },
      "cell_type": "code",
      "source": [
        "# Run the model\n",
        "model = train_model(net,\n",
        "                log_dir,\n",
        "                train_loader,\n",
        "                criterion,\n",
        "                optimizer,\n",
        "                num_epochs, \n",
        "                log_freq,\n",
        "                print_guess=False) # or print_guess=true for pics\n",
        "#                 print_guess=True) # or print_guess=False for tqdm\n",
        "\n",
        "# final_acc = test_model(model, criterion, test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch 0:   0%|          | 0/1000 [00:00<?, ? minibatches/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training model. Logging to: \"./logs/BiggerCNN_lr0.0003 (4394909.0)/\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:  27%|██▋       | 274/1000 [01:40<03:57,  3.05 minibatches/s, loss=0.0825, training_accuracy=0.981]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "jmtx5FYnIIvB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-3x1V0ClK9ZI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}