{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yk33mywbpcxd"
   },
   "source": [
    "# PyTorch Third Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "2JLf_jcWAi26",
    "outputId": "94e3b5e6-361d-49f9-93c8-1035b08b0263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gputil\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
      "Building wheels for collected packages: gputil\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
      "Successfully built gputil\n",
      "Installing collected packages: gputil\n",
      "Successfully installed gputil-1.4.0\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "# # Check out available CPU and GPU memory\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "\n",
    "def print_CPU_GPU_info(GPUs):\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"\\nCPU \\tRAM Free: {humanize.naturalsize(psutil.virtual_memory().available)}\"\n",
    "          f\"    | Proc size: {humanize.naturalsize(process.memory_info().rss)}\")\n",
    "    if GPUs[0]: \n",
    "        for i,gpu in enumerate(GPUs):\n",
    "            print(f\"GPU {i} \\tRAM Free: {gpu.memoryFree/1000:.3f} GB  \"\n",
    "                  f\"| Used: {gpu.memoryUsed/1000:.3f} GB\"\n",
    "                  f\"\\t| Utilization: {gpu.memoryUtil*100:3.0f}% | \"\n",
    "                  f\"Total Memory: {gpu.memoryTotal/1000:.3f} GB\")\n",
    "    else: print(f\"Not on a GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "tl7BZKJuOQ4t",
    "outputId": "1ecb979b-dbfd-4aa2-b94f-5413df46646a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU \tRAM Free: 12.9 GB    | Proc size: 143.1 MB\n",
      "GPU 0 \tRAM Free: 11.441 GB  | Used: 0.000 GB\t| Utilization:   0% | Total Memory: 11.441 GB\n"
     ]
    }
   ],
   "source": [
    "print_CPU_GPU_info(GPU.getGPUs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "OgjeP1M8pcxe",
    "outputId": "f3e820af-9e20-4a48-862f-b24f1d065924"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) { return false; }\n",
       "// disable scrollable cells"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) { return false; }\n",
    "// disable scrollable cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "iX8Q9D1Fpcxj",
    "outputId": "3113889f-0cd8-4953-cd10-5440477d5bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'chess-ray-vision'...\n",
      "remote: Enumerating objects: 80, done.\u001b[K\n",
      "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
      "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
      "remote: Total 80 (delta 11), reused 77 (delta 8), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (80/80), done.\n",
      "Cloning into 'crvdataset'...\n",
      "remote: Enumerating objects: 39509, done.\u001b[K\n",
      "remote: Counting objects: 100% (39509/39509), done.\u001b[K\n",
      "remote: Compressing objects: 100% (39378/39378), done.\u001b[K\n",
      "remote: Total 39509 (delta 150), reused 39484 (delta 128), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (39509/39509), 770.54 MiB | 32.50 MiB/s, done.\n",
      "Resolving deltas: 100% (150/150), done.\n",
      "Checking out files: 100% (39691/39691), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/samryan18/chess-ray-vision\n",
    "! git clone https://github.com/mukundv7/crvdataset\n",
    "! mv chess-ray-vision/clean_notebooks/* .\n",
    "! mkdir train_full\n",
    "! mv crvdataset/chess-positions/train-full/* train_full/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rVc5YZiHpcxl"
   },
   "source": [
    "# Setup Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "G5YloGGWqY72",
    "outputId": "e86fede4-242e-4756-8e6e-d08038bcd19b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.0.1 from https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl (614.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 614.8MB 27kB/s \n",
      "\u001b[31mfastai 1.0.50.post1 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "  Found existing installation: torch 1.0.1.post2\n",
      "    Uninstalling torch-1.0.1.post2:\n",
      "      Successfully uninstalled torch-1.0.1.post2\n",
      "Successfully installed torch-1.0.1\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.1.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Pytorch Colab Setup\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
    "!pip3 install torchvision\n",
    "  \n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "joxmigYl9iK9",
    "outputId": "0130cc63-f1dd-4e7b-fa15-ba31aef1d166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
      "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.1)\n",
      "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.14.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n",
      "Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.1.1)\n",
      "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.1.7)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.9)\n"
     ]
    }
   ],
   "source": [
    "## Required packages (Install in Colab)\n",
    "!pip install tensorflow\n",
    "!pip install scipy\n",
    "!pip install numpy\n",
    "!pip install Pillow\n",
    "!pip install image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wkGhAHeKpcxx",
    "outputId": "7fbd7a82-6aa4-450b-98cc-2eb7a282ff41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np;\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time, datetime\n",
    "from pytorch_general.pytorch_helper import imshow\n",
    "from pytorch_general.tensorboard_helper import Logger\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from random import randint\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Callable\n",
    "import torch\n",
    "import dill\n",
    "import torch.optim as optim\n",
    "device =torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIq7Yn4mpmoD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "piece_symbols = 'prbnkqPRBNKQ'\n",
    "\n",
    "def onehot_from_fen(fen):\n",
    "    eye = np.eye(13)\n",
    "    output = np.empty((0, 13))\n",
    "    fen = re.sub('[-]', '', fen)\n",
    "\n",
    "    for char in fen:\n",
    "        if(char in '12345678'):\n",
    "            output = np.append(\n",
    "              output, np.tile(eye[12], (int(char), 1)), axis=0)\n",
    "        else:\n",
    "            idx = piece_symbols.index(char)\n",
    "            output = np.append(output, eye[idx].reshape((1, 13)), axis=0)\n",
    "\n",
    "    return output\n",
    "\n",
    "def fen_from_onehot(one_hot):\n",
    "    output = ''\n",
    "    for j in range(8):\n",
    "        for i in range(8):\n",
    "            if(one_hot[j][i] == 12):\n",
    "                output += ' '\n",
    "            else:\n",
    "                output += piece_symbols[one_hot[j][i]]\n",
    "        if(j != 7):\n",
    "            output += '-'\n",
    "\n",
    "    for i in range(8, 0, -1):\n",
    "        output = output.replace(' ' * i, str(i))\n",
    "\n",
    "    return output\n",
    "\n",
    "class_prob = onehot_from_fen('4kN1N-B1P5-QQ3B2-R1n1b3-8-1p2P3-1K6-6b1')\n",
    "\n",
    "# one_hot = np.zeros((64, 13))\n",
    "# one_hot[np.arange(64,13), class_labels] = 1\n",
    "# # class_labels\n",
    "# np.shape(class_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzTlMw2xpcx_"
   },
   "outputs": [],
   "source": [
    "def load_batch(directory='train_full/', batch_size=32):\n",
    "    '''\n",
    "    Probably a better way to do this using something like this:\n",
    "    https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py\n",
    "    \n",
    "    This loads a single random batch from the training set.\n",
    "    '''\n",
    "    pathlist = list(Path(directory).glob('**/*.jpeg'))\n",
    "    labels = []\n",
    "    images = []\n",
    "    n_files = len(pathlist)\n",
    "    random_indicies = [randint(0, n_files) for _ in range(batch_size)]\n",
    "\n",
    "    for path in [pathlist[x] for x in random_indicies]:\n",
    "        label = str(path).split(directory)[1].split(f'.')[0]\n",
    "        label = onehot_from_fen(label)\n",
    "\n",
    "        img = np.asarray(Image.open(str(path))).astype('uint8')\n",
    "        labels.append(label)\n",
    "        images.append(img)\n",
    "        \n",
    "    test_images, test_labels = (images, labels) # TODO\n",
    "        \n",
    "    return images, labels, test_images, test_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CustomChessDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, transform=None, root='train_full/', train=True):\n",
    "#         train_images, train_labels, test_images, test_labels = load_datasets()\n",
    "        self.transform = transform\n",
    "\n",
    "        self._train = train\n",
    "            \n",
    "        self.root = root\n",
    "        self.pathlist = list(Path(self.root).glob('**/*.jpeg'))\n",
    "        self.n_files = len(self.pathlist)\n",
    "\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_files\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.pathlist[idx]\n",
    "        label = str(path).split(self.root)[1].split(f'.')[0]\n",
    "        label = onehot_from_fen(label)\n",
    "        img = np.asarray(Image.open(str(path))).astype('uint8')\n",
    "\n",
    "        img_as_img = Image.fromarray(img)\n",
    "        img_as_img = img_as_img.convert('L')\n",
    "        img_as_img = self.transform(img_as_img)\n",
    "        \n",
    "        \n",
    "#         _,class_labels = torch.max(self.to_tensor(self.labels[idx]).long().to(device),1) \n",
    "\n",
    "        return (self.to_tensor(img_as_img), \n",
    "                label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jprHKvxU8D0M"
   },
   "outputs": [],
   "source": [
    "# NEW FROM KERAS VERSION\n",
    "\n",
    "import glob\n",
    "from random import shuffle\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from skimage import transform as sktransform\n",
    "from skimage import io\n",
    "\n",
    "piece_symbols = 'prbnkqPRBNKQ'\n",
    "\n",
    "def fen_from_filename(filename):\n",
    "    base = os.path.basename(filename)\n",
    "    return os.path.splitext(base)[0]\n",
    "\n",
    "def process_image(img, downsample_size = 200):\n",
    "    square_size = int(downsample_size/8)\n",
    "    img_read = io.imread(img)\n",
    "    img_read = sktransform.resize(\n",
    "      img_read, (downsample_size, downsample_size), mode='constant')\n",
    "    tiles = view_as_blocks(img_read, block_shape=(square_size, square_size, 3)).squeeze(axis=2)\n",
    "    return tiles.reshape(64, square_size, square_size, 3)    \n",
    "\n",
    "class CustomChessDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 transform=None,\n",
    "                 root='train_full',\n",
    "                 train_size = 10000,\n",
    "                 test_size = 3000,\n",
    "                 downsample_size = 200,\n",
    "                 train=True):\n",
    "\n",
    "        self._train = train\n",
    "        self.downsample_size = downsample_size\n",
    "            \n",
    "        self.root = root\n",
    "        self.pathlist = list(Path(self.root).glob('**/*.jpeg'))\n",
    "        self.n_files = len(self.pathlist)\n",
    "        \n",
    "        self.train_size = train_size\n",
    "        self.test_size = test_size\n",
    "\n",
    "        self.train = glob.glob(f\"{root}/*.jpeg\")\n",
    "        self.test = glob.glob(f\"{root}/*.jpeg\")\n",
    "\n",
    "        shuffle(self.train)\n",
    "        shuffle(self.test)\n",
    "\n",
    "        self.train = self.train[:self.train_size]\n",
    "        self.test = self.test[:self.test_size]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.train_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.train[idx]\n",
    "        label = onehot_from_fen(fen_from_filename(img))\n",
    "        img_as_img = process_image(img, downsample_size = self.downsample_size)\n",
    "\n",
    "        return ((torch.from_numpy(img_as_img).float()), \n",
    "                label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eyai4agLpcyB"
   },
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "batch_size=10 # this needs to be small ish bc bigger models will scale memory usage exponentially\n",
    "downsample_size=200\n",
    "transform = transforms.Compose([transforms.Resize(downsample_size)])\n",
    "\n",
    "train_dataset = CustomChessDataset(root='train_full/', train=True, downsample_size=downsample_size)\n",
    "test_dataset = CustomChessDataset(root='train_full/', train=False, downsample_size=downsample_size)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L84LWc3jpcyL"
   },
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, \n",
    "                log_dir: str,\n",
    "                train_loader,\n",
    "                criterion,\n",
    "                optimizer,\n",
    "                num_epochs,\n",
    "               log_freq,\n",
    "               max_per_epoch=-1) -> nn.Module:\n",
    "    t = datetime.datetime.now()\n",
    "    now = time.mktime(t.timetuple()) - 1550000000\n",
    "    logger = Logger(f'{log_dir} ({now})/')\n",
    "    \n",
    "    print(now)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}')\n",
    "        running_loss = 0\n",
    "        step = 0\n",
    "#         for step, (images, labels) in tqdm_notebook(enumerate(train_loader), total=len(train_loader), unit=\"mini-batches\"):\n",
    "        for step, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            images, labels = images.to(device), labels.long().to(device)\n",
    "\n",
    "\n",
    "            output = model(images).to(device)\n",
    "            _,class_labels = torch.max(labels,1) \n",
    "            loss = criterion(output, class_labels).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, argmax = torch.max(output, 1)\n",
    "            accuracy = float((class_labels == argmax.squeeze()).float().mean().cpu())\n",
    "\n",
    "            running_loss += float(loss.item())\n",
    "            \n",
    "            del(images)\n",
    "            del(labels)\n",
    "            del(class_labels)\n",
    "            \n",
    "            if step % log_freq == 0:\n",
    "\n",
    "                overall_step = epoch*total_step + step\n",
    "\n",
    "                # 1. Log scalar values (scalar summary)\n",
    "                info = { 'loss': loss.item(), 'accuracy': accuracy }\n",
    "\n",
    "                for key, value in info.items():\n",
    "                    logger.scalar_summary(key, value, overall_step)\n",
    "\n",
    "                # 2. Log values and gradients of the parameters (histogram summary)\n",
    "                for key, value in model.named_parameters():\n",
    "                    key = key.replace('.', '/')\n",
    "                    logger.histo_summary(key, value.data.cpu().numpy(), overall_step)\n",
    "                    try:\n",
    "                        logger.histo_summary(key+'/grad', value.grad.data.cpu().numpy(), overall_step)\n",
    "                    except (AttributeError):\n",
    "                        # During transfer learning some of the variables don't have grads\n",
    "                        pass\n",
    "            \n",
    "            if max_per_epoch > 0 and step > max_per_epoch:\n",
    "                break\n",
    "        \n",
    "        print(f\"{epoch}: Training loss: {running_loss/len(train_loader)}\")\n",
    "        print(f\"{epoch}: Training accuracy: {accuracy}\")\n",
    " \n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(model, criterion, test_loader) -> float:\n",
    "    model = model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    total_step = len(test_loader)\n",
    "    with torch.no_grad():\n",
    "        for i in range(total_step):\n",
    "            for  images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.long().to(device)\n",
    "                _,class_labels = torch.max(labels,1) \n",
    "\n",
    "                output = model(images).to(device)\n",
    "                loss = criterion(output, class_labels)\n",
    "                losses.append(float(loss.item()))\n",
    "\n",
    "\n",
    "                # Compute accuracy\n",
    "                _, argmax = torch.max(output, 1)\n",
    "                accuracy = float((class_labels == argmax.squeeze()).float().mean().cpu())\n",
    "                accuracies.append(accuracy)\n",
    "                \n",
    "    print(f'Accuracy of the network on test images: {np.average(accuracies)}')\n",
    "    print(f'Avg. Loss of the network on test images: {np.average(losses)}')\n",
    "\n",
    "    return np.average(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRQAmGX57yo0"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1) \n",
    "\n",
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.name = 'SimpleCNN'\n",
    "        self.batch_size=batch_size\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1),\n",
    "            nn.LeakyReLU(negative_slope=0.1))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1),\n",
    "            nn.ReLU())\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1),\n",
    "            nn.ReLU())\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(32*19*19, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.1))\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, 13))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(self.batch_size*64,3,25,25)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "#         print(f'xsize: {x.size()}')\n",
    "        x = x.reshape(self.batch_size,64,13)\n",
    "\n",
    "        return(x)\n",
    "    \n",
    "class BiggerCNN(torch.nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super(BiggerCNN, self).__init__()\n",
    "        self.name = 'BiggerCNN'\n",
    "        self.batch_size=batch_size\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.LeakyReLU(negative_slope=0.1))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU())\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU())\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(64*19*19, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.1))\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.1))\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(256, 13))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(self.batch_size*64,3,25,25)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "#         print(f'xsize: {x.size()}')\n",
    "        x = x.reshape(self.batch_size,64,13)\n",
    "\n",
    "        return(x)\n",
    "    \n",
    "class BatchNormBiggerCNN(torch.nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super(BatchNormBiggerCNN, self).__init__()\n",
    "        self.name = 'BatchNormBiggerCNN'\n",
    "        self.batch_size=batch_size\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(p = 0.1))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.1))\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU())\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(64*19*19, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.1))\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.1))\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(256, 13))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(self.batch_size*64,3,25,25)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "#         print(f'xsize: {x.size()}')\n",
    "        x = x.reshape(self.batch_size,64,13)\n",
    "\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QaHWGkUssACN"
   },
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# summary(net, input_size=(64, 32, 25, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KxR7xzEFMaPR",
    "outputId": "9a510599-f420-4fd4-fccc-4447bfa79665"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngrok already installed\n",
      "Tensorboard Link: http://aec27de6.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = './logs'\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "\n",
    "!if [ -f ngrok ] ; then echo \"Ngrok already installed\" ; else wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1 && unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1 ; fi\n",
    "\n",
    "get_ipython().system_raw('./ngrok http 6006 &')\n",
    "\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7c-HvzxJMddu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "2W2kijdBpcyV",
    "outputId": "2d821e92-0f56-471f-ef74-ef44d5b64078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4252158.0\n",
      "Epoch 0\n",
      "0: Training loss: 1.2905190806314348\n",
      "0: Training accuracy: 0.9769230484962463\n",
      "Epoch 1\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "log_freq=20\n",
    "\n",
    "# 0.0005 best so far\n",
    "learning_rates = [ 0.0004, 0.0002, 0.0007]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    \n",
    "    net = BiggerCNN(batch_size=batch_size)\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = f'./logs/{net.name}_lr{learning_rate}'\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    model = train_model(net,\n",
    "                    log_dir,\n",
    "                    train_loader,\n",
    "                    criterion,\n",
    "                    optimizer,\n",
    "                    num_epochs, \n",
    "                    log_freq,\n",
    "                    max_per_epoch=-1) # max per epoch is a debugging thing\n",
    "\n",
    "# final_acc = test_model(model, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2lxZFKlsUOR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOU7Z3gxpcyt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Za8WUOnFHWEu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJAB_gjrHWJ1"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# from matplotlib.pyplot import imshow\n",
    "# import matplotlib.pyplot as plt\n",
    "from utils.draw_chess_boards import *\n",
    "\n",
    "renderer = DrawChessPosition(delimiter='-')\n",
    "fen = \"r2q1rk1/pp2ppbp/1np2np1/2Q3B1/3PP1b1/2N2N2/PP3PPP/3RKB1R\"\n",
    "fen = \"rnbqkbnr-pppppppp-8-8-8-8-PPPPPPPP-RNBQKBNR\"\n",
    "board = renderer.draw(fen)\n",
    "renderer.show(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ywR6A-Gepcy_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_Model_Third_Attempt.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
