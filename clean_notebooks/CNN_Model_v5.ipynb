{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Model_v5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "Yk33mywbpcxd"
      },
      "cell_type": "markdown",
      "source": [
        "# PyTorch Model on Dummy Dataset (v5)\n",
        "\n",
        "#### Chess Board Object Detection\n",
        "\n",
        "#### CIS 520, Spring 2019\n",
        "\n",
        "This notebook is written to run on [Google Colab](https://colab.research.google.com/notebook). \n",
        "\n",
        "----\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2JLf_jcWAi26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "004c430c-3fa6-49d6-defd-650ff3ab185a"
      },
      "cell_type": "code",
      "source": [
        "# # Check out available CPU and GPU memory\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "def print_CPU_GPU_info(GPUs):\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(f\"\\nCPU \\tRAM Free: {humanize.naturalsize(psutil.virtual_memory().available)}\"\n",
        "          f\"    | Proc size: {humanize.naturalsize(process.memory_info().rss)}\")\n",
        "    if GPUs[0]: \n",
        "        for i,gpu in enumerate(GPUs):\n",
        "            print(f\"GPU {i} \\tRAM Free: {gpu.memoryFree/1000:.3f} GB  \"\n",
        "                  f\"| Used: {gpu.memoryUsed/1000:.3f} GB\"\n",
        "                  f\"\\t| Utilization: {gpu.memoryUtil*100:3.0f}% | \"\n",
        "                  f\"Total Memory: {gpu.memoryTotal/1000:.3f} GB\")\n",
        "    else: print(f\"Not on a GPU\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tl7BZKJuOQ4t",
        "outputId": "859fb571-3c6b-4a7c-baa9-38f7492907c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print_CPU_GPU_info(GPU.getGPUs())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU \tRAM Free: 12.7 GB    | Proc size: 142.2 MB\n",
            "GPU 0 \tRAM Free: 11.441 GB  | Used: 0.000 GB\t| Utilization:   0% | Total Memory: 11.441 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OgjeP1M8pcxe",
        "outputId": "a5845d2f-b1b6-4ec3-98c7-b8513c4c2ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "cell_type": "code",
      "source": [
        "%%javascript\n",
        "IPython.OutputArea.prototype._should_scroll = function(lines) { return false; }\n",
        "// disable scrollable cells"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.OutputArea.prototype._should_scroll = function(lines) { return false; }\n",
              "// disable scrollable cells"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "c6f5WavtHSJb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # ! rm -rf pytorch_general\n",
        "# # ! rm pytorch_general\n",
        "# # ! rm -rf images\n",
        "# # ! rm -rf piece_images\n",
        "# ! rm -rf chess-ray-vision\n",
        "# ! rm -rf utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iX8Q9D1Fpcxj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e6f04a66-f361-46ea-f590-be5f6a96e038"
      },
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/samryan18/chess-ray-vision\n",
        "! mv chess-ray-vision/clean_notebooks/* .\n",
        "\n",
        "\n",
        "#NOTE this next line will download 2+ GB of data\n",
        "#Do not run locally unless your comp can take that kinda heat\n",
        "! git clone https://github.com/mukundv7/crvdataset \n",
        "! mkdir train_full\n",
        "! mv crvdataset/chess-positions/train-full/* train_full/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'chess-ray-vision' already exists and is not an empty directory.\n",
            "mv: cannot stat 'chess-ray-vision/clean_notebooks/*': No such file or directory\n",
            "fatal: destination path 'crvdataset' already exists and is not an empty directory.\n",
            "mkdir: cannot create directory ‘train_full’: File exists\n",
            "mv: cannot stat 'crvdataset/chess-positions/train-full/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "rVc5YZiHpcxl"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup Stuff"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "G5YloGGWqY72",
        "outputId": "ec050c98-5c6a-4626-c764-e5f096f183f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "# Pytorch Colab Setup\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "  \n",
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.0.1 from https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "joxmigYl9iK9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "700312de-98a5-4a2d-891c-641ef4f2e4e9"
      },
      "cell_type": "code",
      "source": [
        "## Required packages (Install in Colab)\n",
        "!pip install tensorflow\n",
        "!pip install scipy\n",
        "!pip install numpy\n",
        "!pip install Pillow\n",
        "!pip install image\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.8.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.14.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n",
            "Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.1.7)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.1.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.9)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wkGhAHeKpcxx",
        "outputId": "0ee52467-c756-4744-ca7b-b43af6ac3eae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "####################################################\n",
        "# CODE IMPORTS\n",
        "\n",
        "from pytorch_general.pytorch_helper import imshow\n",
        "from pytorch_general.tensorboard_helper import Logger\n",
        "from utils.data_loading_utils import (onehot_from_fen, fen_from_onehot, \n",
        "                                     fen_from_64, fen_from_filename, \n",
        "                                     process_image)\n",
        "from utils.draw_chess_boards import DrawChessPosition\n",
        "\n",
        "####################################################\n",
        "# EXTERNAL IMPORTS\n",
        "\n",
        "import torchvision\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import numpy as np;\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time, datetime\n",
        "from tqdm import tqdm\n",
        "from torchsummary import summary\n",
        "\n",
        "from random import randint\n",
        "\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from random import shuffle\n",
        "import os\n",
        "\n",
        "\n",
        "import glob\n",
        "\n",
        "import torch.optim as optim\n",
        "device =torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OIq7Yn4mpmoD",
        "outputId": "fb7fed27-6564-4fee-8daf-4bf54f43cdba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "fen = '4kN1N-bbbbbbbb-QQ3B2-R1n1b3-8-8-ppqKbKbk-8'\n",
        "class_prob = onehot_from_fen(fen)\n",
        "\n",
        "print(f\"Original: \\t{fen}\")\n",
        "print(f\"Reconstructed:  {fen_from_onehot(class_prob)}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: \t4kN1N-bbbbbbbb-QQ3B2-R1n1b3-8-8-ppqKbKbk-8\n",
            "Reconstructed:  4kN1N-bbbbbbbb-QQ3B2-R1n1b3-8-8-ppqKbKbk-8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jprHKvxU8D0M",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CustomChessDataset(Dataset):\n",
        "    \"\"\"Chess dataset\"\"\"\n",
        "\n",
        "    def __init__(self, \n",
        "                 transform=None,\n",
        "                 root='train_full',\n",
        "                 train_size = 10000,\n",
        "                 test_size = 3000,\n",
        "                 downsample_size = 200,\n",
        "                 train=True):\n",
        "\n",
        "        self._train = train\n",
        "        self.downsample_size = downsample_size\n",
        "            \n",
        "        self.root = root\n",
        "        self.pathlist = list(Path(self.root).glob('**/*.jpeg'))\n",
        "        self.n_files = len(self.pathlist)\n",
        "        \n",
        "        self.train_size = train_size\n",
        "        self.test_size = test_size\n",
        "\n",
        "        self.train = glob.glob(f\"{root}/*.jpeg\")\n",
        "        self.test = glob.glob(f\"{root}/*.jpeg\")\n",
        "\n",
        "        shuffle(self.train)\n",
        "        shuffle(self.test)\n",
        "\n",
        "        self.train = self.train[:self.train_size]\n",
        "        self.test = self.test[:self.test_size]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.train_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.train[idx]\n",
        "        label = onehot_from_fen(fen_from_filename(img))\n",
        "        img_as_img, original_img = process_image(img, \n",
        "                                                 downsample_size = self.downsample_size)\n",
        "\n",
        "        return ((torch.from_numpy(img_as_img).float()), \n",
        "                label,\n",
        "                original_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eyai4agLpcyB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# BATCH_SIZE needs to be small ish bc bigger models will scale \n",
        "# memory usage exponentially\n",
        "BATCH_SIZE=10 \n",
        "downsample_size=200\n",
        "transform = transforms.Compose([transforms.Resize(downsample_size)])\n",
        "\n",
        "train_dataset = CustomChessDataset(root='train_full/', train=True, \n",
        "                                   downsample_size=downsample_size)\n",
        "test_dataset = CustomChessDataset(root='train_full/', train=False, \n",
        "                                  downsample_size=downsample_size)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L84LWc3jpcyL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model: nn.Module, \n",
        "                log_dir: str,\n",
        "                train_loader: torch.utils.data.DataLoader,\n",
        "                criterion: torch.nn.modules.Module,\n",
        "                optimizer: torch.optim.Optimizer,\n",
        "                num_epochs: int=1,\n",
        "                log_freq: int=25,\n",
        "                print_guess=False,\n",
        "                print_guess_freq=50) -> nn.Module:\n",
        "    \n",
        "    # Create Logging Directory for Tensorboard\n",
        "    now = time.mktime(datetime.datetime.now().timetuple()) - 1550000000\n",
        "    log_dir = f'{log_dir} ({now})/'\n",
        "    logger = Logger(log_dir)\n",
        "    print(f'Training model. Logging to: \"{log_dir}\"\\n')\n",
        "\n",
        "    model = model.to(device) # Send model to GPU if possible\n",
        "    model.train() # Set model to training mode\n",
        "\n",
        "    total_step = len(train_loader)\n",
        "    for epoch in range(num_epochs):\n",
        "        if print_guess: print(f'Epoch {epoch}')\n",
        "        running_loss = 0\n",
        "        \n",
        "        # Tqdm will create a progress bar\n",
        "        with tqdm(total=len(train_loader), \n",
        "                  desc=f'Epoch {epoch}', \n",
        "                  unit=' minibatches',\n",
        "                  disable=(print_guess)) as pbar:\n",
        "            \n",
        "            # Iterate through minibatches\n",
        "            for step, (images, labels, original_imgs) in enumerate(train_loader):\n",
        "                images, labels = images.to(device), labels.long().to(device)\n",
        "\n",
        "                output = model(images).to(device)\n",
        "                _,class_labels = torch.max(labels,2) \n",
        "                _, argmax = torch.max(output, 2)\n",
        "\n",
        "                accuracy = float((class_labels == \n",
        "                                  argmax.squeeze()).float().mean().cpu())\n",
        "\n",
        "                loss = criterion(output.reshape(10*64,13).float(),\n",
        "                                 class_labels.reshape(10*64))\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "\n",
        "                running_loss += float(loss.item())\n",
        "                \n",
        "                pbar.set_postfix(training_accuracy=accuracy, loss=loss.item(), refresh=True)\n",
        "                pbar.update(1)\n",
        "                \n",
        "                if step % log_freq == 0:\n",
        "                    overall_step = epoch*total_step + step\n",
        "\n",
        "                    # 1. Log scalar values (scalar summary)\n",
        "                    info = { 'loss': loss.item(), 'accuracy': accuracy }\n",
        "\n",
        "                    for key, value in info.items():\n",
        "                        logger.scalar_summary(key, value, overall_step)\n",
        "\n",
        "                    # 2. Log values and gradients of the parameters\n",
        "                    # (histogram summary)\n",
        "                    for key, value in model.named_parameters():\n",
        "                        key = key.replace('.', '/')\n",
        "                        logger.histo_summary(key, \n",
        "                                             value.data.cpu().numpy(), \n",
        "                                             overall_step)\n",
        "                        try:\n",
        "                            logger.histo_summary(key+'/grad', \n",
        "                                                 value.grad.data.cpu().numpy(),\n",
        "                                                 overall_step)\n",
        "                        except (AttributeError):\n",
        "                            # During transfer learning some of the variables \n",
        "                            # don't have grads\n",
        "                            pass\n",
        "    \n",
        "                if print_guess and step % print_guess_freq == 0:\n",
        "\n",
        "                    overall_step = epoch*total_step + step\n",
        "                    print(f\"\\n{60*'-'}\\nBatch Number: {overall_step}\")\n",
        "                    print(f\"Example training point:\")\n",
        "                    print(f\"Actual: {fen_from_64(class_labels.cpu()[0])}\")\n",
        "                    print(f\"Guess: {fen_from_64(argmax.cpu()[0])}\")\n",
        "                    print(f\"Example Accuracy: {float((class_labels[0] == argmax[0]).float().mean().cpu())}\")\n",
        "                    \n",
        "                    renderer = DrawChessPosition(delimiter='-')\n",
        "                    board_actual = renderer.draw(fen_from_64(class_labels.cpu()[0]))\n",
        "                    board_guess = renderer.draw(fen_from_64(argmax.cpu()[0]))\n",
        "                    renderer.show_side_by_side(board1= original_imgs[0],\n",
        "                                               board2=board_guess, \n",
        "                                               board1_title='Actual',\n",
        "                                               board2_title='Prediction (Re'\n",
        "                                                            'ndered to image)')\n",
        "        print(f\"{epoch}: Training loss: {running_loss/len(train_loader)}\")\n",
        "        print(f\"{epoch}: Training accuracy: {accuracy}\")\n",
        " \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def test_model(model, criterion, test_loader) -> float:\n",
        "    \n",
        "    '''\n",
        "    TODO: REWRITE THIS\n",
        "    '''\n",
        "    model = model.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    accuracies = []\n",
        "    losses = []\n",
        "    total_step = len(test_loader)\n",
        "    with torch.no_grad():\n",
        "        for i in range(total_step):\n",
        "            for  images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.long().to(device)\n",
        "                _,class_labels = torch.max(labels,1) \n",
        "\n",
        "                output = model(images).to(device)\n",
        "                loss = criterion(output, class_labels)\n",
        "                losses.append(float(loss.item()))\n",
        "\n",
        "\n",
        "                # Compute accuracy\n",
        "                _, argmax = torch.max(output, 1)\n",
        "                accuracy = float((class_labels == argmax.squeeze()).float().mean().cpu())\n",
        "                accuracies.append(accuracy)\n",
        "                \n",
        "    print(f'Accuracy of the network on test images: {np.average(accuracies)}')\n",
        "    print(f'Avg. Loss of the network on test images: {np.average(losses)}')\n",
        "\n",
        "    return np.average(accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LC5DpAfNRVUL"
      },
      "cell_type": "markdown",
      "source": [
        "# Models"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HRQAmGX57yo0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1) \n",
        "\n",
        "class SimpleCNN(torch.nn.Module):\n",
        "    def __init__(self, batch_size):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.name = 'SimpleCNN'\n",
        "        self.batch_size=batch_size\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1),\n",
        "            nn.LeakyReLU(negative_slope=0.1))\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1),\n",
        "            nn.ReLU())\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1),\n",
        "            nn.ReLU())\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(32*19*19, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.1))\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(256, 13))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(self.batch_size*64,3,25,25)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        \n",
        "        x = self.flatten(x)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "#         print(f'xsize: {x.size()}')\n",
        "        x = x.reshape(self.batch_size,64,13)\n",
        "\n",
        "        return(x)\n",
        "    \n",
        "class BiggerCNN(torch.nn.Module):\n",
        "    def __init__(self, batch_size):\n",
        "        super(BiggerCNN, self).__init__()\n",
        "        self.name = 'BiggerCNN'\n",
        "        self.batch_size=batch_size\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.LeakyReLU(negative_slope=0.1))\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.ReLU())\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.ReLU())\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(64*19*19, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.1))\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.1))\n",
        "        self.fc3 = nn.Sequential(\n",
        "            nn.Linear(256, 13))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(self.batch_size*64,3,25,25)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        \n",
        "        x = self.flatten(x)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "#         print(f'xsize: {x.size()}')\n",
        "        x = x.reshape(self.batch_size,64,13)\n",
        "\n",
        "        return(x)\n",
        "    \n",
        "# class BatchNormBiggerCNN(torch.nn.Module):\n",
        "#     def __init__(self, batch_size):\n",
        "#         super(BatchNormBiggerCNN, self).__init__()\n",
        "#         self.name = 'BatchNormBiggerCNN'\n",
        "#         self.batch_size=batch_size\n",
        "#         self.conv1 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1),\n",
        "#             nn.BatchNorm2d(64),\n",
        "#             nn.LeakyReLU(negative_slope=0.1),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.conv2 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "#             nn.BatchNorm2d(64),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.conv3 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "#             nn.ReLU())\n",
        "#         self.flatten = Flatten()\n",
        "#         self.fc1 = nn.Sequential(\n",
        "#             nn.Linear(64*19*19, 512),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.fc2 = nn.Sequential(\n",
        "#             nn.Linear(512, 256),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(p = 0.1))\n",
        "#         self.fc3 = nn.Sequential(\n",
        "#             nn.Linear(256, 13))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = x.reshape(self.batch_size*64,3,25,25)\n",
        "\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.conv2(x)\n",
        "#         x = self.conv3(x)\n",
        "        \n",
        "#         x = self.flatten(x)\n",
        "        \n",
        "#         x = self.fc1(x)\n",
        "#         x = self.fc2(x)\n",
        "#         x = self.fc3(x)\n",
        "\n",
        "# #         print(f'xsize: {x.size()}')\n",
        "#         x = x.reshape(self.batch_size,64,13)\n",
        "\n",
        "#         return(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ctTrYhJWRYQ8"
      },
      "cell_type": "markdown",
      "source": [
        "# Run it..."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KxR7xzEFMaPR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "!if [ -f ngrok ] ; then echo \"Ngrok already installed\" ; else wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1 && unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1 ; fi\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2W2kijdBpcyV",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "log_freq=20\n",
        "\n",
        "\n",
        "learning_rate = 0.0003\n",
        "    \n",
        "net = BiggerCNN(batch_size=BATCH_SIZE)\n",
        "\n",
        "# print a summary of the net statistics\n",
        "summary(net.to(device), (BATCH_SIZE*32, 3, 25, 25))\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "log_dir = f'./logs/{net.name}_lr{learning_rate}'\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "model = train_model(net,\n",
        "                log_dir,\n",
        "                train_loader,\n",
        "                criterion,\n",
        "                optimizer,\n",
        "                num_epochs, \n",
        "                log_freq,\n",
        "                print_guess=True)\n",
        "\n",
        "# final_acc = test_model(model, criterion, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jmtx5FYnIIvB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2071
        },
        "outputId": "142671ab-2227-4083-ea37-31f81aa4e675"
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "log_freq=20\n",
        "\n",
        "\n",
        "learning_rate = 0.0003\n",
        "    \n",
        "net = BiggerCNN(batch_size=BATCH_SIZE)\n",
        "\n",
        "# print a summary of the net statistics\n",
        "summary(net.to(device), (BATCH_SIZE*32, 3, 25, 25))\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "log_dir = f'./logs/{net.name}_lr{learning_rate}'\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "model = train_model(net,\n",
        "                log_dir,\n",
        "                train_loader,\n",
        "                criterion,\n",
        "                optimizer,\n",
        "                num_epochs, \n",
        "                log_freq,\n",
        "                print_guess=False)\n",
        "\n",
        "# final_acc = test_model(model, criterion, test_loader)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch 0:   0%|          | 0/1000 [00:00<?, ? minibatches/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 23, 23]           1,792\n",
            "         LeakyReLU-2           [-1, 64, 23, 23]               0\n",
            "            Conv2d-3           [-1, 64, 21, 21]          36,928\n",
            "              ReLU-4           [-1, 64, 21, 21]               0\n",
            "            Conv2d-5           [-1, 64, 19, 19]          36,928\n",
            "              ReLU-6           [-1, 64, 19, 19]               0\n",
            "           Flatten-7                [-1, 23104]               0\n",
            "            Linear-8                  [-1, 512]      11,829,760\n",
            "              ReLU-9                  [-1, 512]               0\n",
            "          Dropout-10                  [-1, 512]               0\n",
            "           Linear-11                  [-1, 256]         131,328\n",
            "             ReLU-12                  [-1, 256]               0\n",
            "          Dropout-13                  [-1, 256]               0\n",
            "           Linear-14                   [-1, 13]           3,341\n",
            "================================================================\n",
            "Total params: 12,040,077\n",
            "Trainable params: 12,040,077\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 2.29\n",
            "Forward/backward pass size (MB): 1.49\n",
            "Params size (MB): 45.93\n",
            "Estimated Total Size (MB): 49.71\n",
            "----------------------------------------------------------------\n",
            "Training model. Logging to: \"./logs/BiggerCNN_lr0.0003 (4329559.0)/\"\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:   5%|▍         | 47/1000 [00:16<05:24,  2.94 minibatches/s, loss=0.376, training_accuracy=0.911]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-87b409b7e3af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mlog_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 print_guess=False)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# final_acc = test_model(model, criterion, test_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-45be3718e4a9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, log_dir, train_loader, criterion, optimizer, num_epochs, log_freq, print_guess, print_guess_freq)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Iterate through minibatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_imgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-0efe30c43dac>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_from_fen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfen_from_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         img_as_img, original_img = process_image(img, \n\u001b[0;32m---> 39\u001b[0;31m                                                  downsample_size = self.downsample_size)\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         return ((torch.from_numpy(img_as_img).float()), \n",
            "\u001b[0;32m/content/utils/data_loading_utils.py\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(img, downsample_size)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0msquare_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownsample_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     img = sktransform.resize(io.imread(img), \n\u001b[0m\u001b[1;32m     70\u001b[0m                                   \u001b[0;34m(\u001b[0m\u001b[0mdownsample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                                   mode='constant')\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_grey, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                                (plugin, kind))\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, img_num, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mpil_to_ndarray\u001b[0;34m(im, dtype, img_num)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# this will raise an IOError if the file is not readable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0msite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://pillow.readthedocs.org/en/latest/installation.html#external-libraries\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mgetdata\u001b[0;34m(self, band)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \"\"\"\n\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mband\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetband\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                         \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-3x1V0ClK9ZI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}